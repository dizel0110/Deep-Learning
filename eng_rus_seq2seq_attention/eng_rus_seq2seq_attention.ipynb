{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"eng_rus_seq2seq_attention.ipynb","provenance":[{"file_id":"1OYzlqXRnnAbkDwokKbOYuvXCfxbZ6lnf","timestamp":1585810119247},{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/seq2seq_translation_tutorial.ipynb","timestamp":1584645023061}]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-YlRH3mQM9tf"},"source":["%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIEGXF8oM9tt"},"source":["from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5dUnh2XeXKKs","executionInfo":{"status":"ok","timestamp":1615313091728,"user_tz":-180,"elapsed":34146,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"b0a1400a-182e-4b8f-f56c-5698cf1e85f7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lJ1Q1b2MXKis"},"source":["data_dir = '/content/drive/My Drive/Colab Notebooks/eng_rus_seq2seq_attention/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"2vi7mdN-XOJf","executionInfo":{"status":"ok","timestamp":1615313096903,"user_tz":-180,"elapsed":622,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"5f10b0da-75ca-4a6e-c29f-bb285486a59e"},"source":["data_dir"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/eng_rus_seq2seq_attention/'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"8UKlPFcBNZl5","colab":{"base_uri":"https://localhost:8080/","height":618},"executionInfo":{"status":"ok","timestamp":1585810269728,"user_tz":-180,"elapsed":10018,"user":{"displayName":"Алексей Кузьмин","photoUrl":"","userId":"13824739836143424630"}},"outputId":"56f5b488-68a9-42f9-cadd-7e8425bf8d98"},"source":["!wget https://download.pytorch.org/tutorial/data.zip\n","!unzip data.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-04-02 06:51:04--  https://download.pytorch.org/tutorial/data.zip\n","Resolving download.pytorch.org (download.pytorch.org)... 54.192.87.92, 54.192.87.42, 54.192.87.67, ...\n","Connecting to download.pytorch.org (download.pytorch.org)|54.192.87.92|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2882130 (2.7M) [application/zip]\n","Saving to: ‘data.zip’\n","\n","\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  17.6MB/s    in 0.2s    \n","\n","2020-04-02 06:51:04 (17.6 MB/s) - ‘data.zip’ saved [2882130/2882130]\n","\n","Archive:  data.zip\n","   creating: data/\n","  inflating: data/eng-fra.txt        \n","   creating: data/names/\n","  inflating: data/names/Arabic.txt   \n","  inflating: data/names/Chinese.txt  \n","  inflating: data/names/Czech.txt    \n","  inflating: data/names/Dutch.txt    \n","  inflating: data/names/English.txt  \n","  inflating: data/names/French.txt   \n","  inflating: data/names/German.txt   \n","  inflating: data/names/Greek.txt    \n","  inflating: data/names/Irish.txt    \n","  inflating: data/names/Italian.txt  \n","  inflating: data/names/Japanese.txt  \n","  inflating: data/names/Korean.txt   \n","  inflating: data/names/Polish.txt   \n","  inflating: data/names/Portuguese.txt  \n","  inflating: data/names/Russian.txt  \n","  inflating: data/names/Scottish.txt  \n","  inflating: data/names/Spanish.txt  \n","  inflating: data/names/Vietnamese.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"twIcAJnyRkW-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615313103065,"user_tz":-180,"elapsed":1786,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"2ac21d9f-43df-4bac-a45a-4423101f3bea"},"source":["!tail '/content/drive/My Drive/Colab Notebooks/eng_rus_seq2seq_attention/eng-rus.txt'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tom said, \"You can kiss your girlfriend goodbye if you don't kiss her goodbye,\" which meant, \"If you don't kiss your girlfriend goodbye, then you'll never see her again.\"\t«Можешь попрощаться со своей подружкой, если ты с ней не попрощаешься», — сказал Том, что означало «если ты не попрощаешься со своей подружкой, то больше ты её никогда не увидишь».\tCC-BY 2.0 (France) Attribution: tatoeba.org #1065032 (CK) & #4435211 (sharptoothed)\n","The more countries a language is spoken in, the less important it is to sound like a native speaker, since speakers of that language are accustomed to hearing various dialects.\tЧем в большем количестве стран используется тот или иной язык, тем менее важно иметь такое же произношение, как у его носителей, так как носители этого языка привыкли к звучанию различных акцентов.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954354 (CK) & #4465953 (Wezel)\n","A mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\tОшибка, которую часто делают молодые, — начинают учить слишком много языков одновременно: они недооценивают трудности и переоценивают свои способности к изучению.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2783162 (catcher) & #5118905 (Wezel)\n","We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (CO) & #6390439 (odexed)\n","I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (CO) & #6390123 (odexed)\n","In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (CO) & #5968115 (odexed)\n","Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n","At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (CO) & #4509418 (odexed)\n","Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n","Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZKGK6tgcX8xO"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yomq6VENX9I0"},"source":["df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/eng_rus_seq2seq/eng-rus.txt', sep='\\t', header=None).drop(2, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197},"id":"snmTAd0KX9U1","executionInfo":{"status":"ok","timestamp":1615313116114,"user_tz":-180,"elapsed":799,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"37680f5c-9138-46d1-ff55-1eb17a29d610"},"source":["df.tail(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>421760</th>\n","      <td>In today's world, we have to equip all our kid...</td>\n","      <td>В современном мире перед нами стоит задача дат...</td>\n","    </tr>\n","    <tr>\n","      <th>421761</th>\n","      <td>Death is something that we're often discourage...</td>\n","      <td>Смерть - это зачастую то, разговоры или даже м...</td>\n","    </tr>\n","    <tr>\n","      <th>421762</th>\n","      <td>At a moment when our economy is growing, our b...</td>\n","      <td>В тот момент, когда наша экономика растёт, наш...</td>\n","    </tr>\n","    <tr>\n","      <th>421763</th>\n","      <td>Since there are usually multiple websites on a...</td>\n","      <td>Поскольку сайтов, посвящённых какой-либо теме,...</td>\n","    </tr>\n","    <tr>\n","      <th>421764</th>\n","      <td>Doubtless there exists in this world precisely...</td>\n","      <td>Несомненно, для каждого мужчины в этом мире гд...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                        0                                                  1\n","421760  In today's world, we have to equip all our kid...  В современном мире перед нами стоит задача дат...\n","421761  Death is something that we're often discourage...  Смерть - это зачастую то, разговоры или даже м...\n","421762  At a moment when our economy is growing, our b...  В тот момент, когда наша экономика растёт, наш...\n","421763  Since there are usually multiple websites on a...  Поскольку сайтов, посвящённых какой-либо теме,...\n","421764  Doubtless there exists in this world precisely...  Несомненно, для каждого мужчины в этом мире гд..."]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Nay9IwEvX9ff"},"source":["df.to_csv('/content/drive/My Drive/Colab Notebooks/eng_rus_seq2seq_attention/eng_rus.txt', header=False, index=False, sep='\\t', mode='a')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cy7yxECDYTIs","executionInfo":{"status":"ok","timestamp":1615313158798,"user_tz":-180,"elapsed":968,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"e0e817df-ac5f-4b85-83bd-1ab0a7d6fabf"},"source":["!tail '/content/drive/My Drive/Colab Notebooks/eng_rus_seq2seq_attention/eng_rus.txt'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"Tom said, \"\"You can kiss your girlfriend goodbye if you don't kiss her goodbye,\"\" which meant, \"\"If you don't kiss your girlfriend goodbye, then you'll never see her again.\"\"\"\t«Можешь попрощаться со своей подружкой, если ты с ней не попрощаешься», — сказал Том, что означало «если ты не попрощаешься со своей подружкой, то больше ты её никогда не увидишь».\n","The more countries a language is spoken in, the less important it is to sound like a native speaker, since speakers of that language are accustomed to hearing various dialects.\tЧем в большем количестве стран используется тот или иной язык, тем менее важно иметь такое же произношение, как у его носителей, так как носители этого языка привыкли к звучанию различных акцентов.\n","A mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\tОшибка, которую часто делают молодые, — начинают учить слишком много языков одновременно: они недооценивают трудности и переоценивают свои способности к изучению.\n","We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\n","I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\n","In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\n","Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\n","At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\n","Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\t\"Поскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"\"назад\"\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\"\n","Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2qIigMGQYTWY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyNnJyruM9t1"},"source":["SOS_token = 0\n","EOS_token = 1\n","\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXKs8j4bM9t6"},"source":["# Turn a Unicode string to plain ASCII, thanks to\n","# http://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# Lowercase, trim, and remove non-letter characters\n","\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zа-яёA-ZА-ЯЁ.!?]+\", r\" \", s)\n","    return s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8T4VxZeM9t-"},"source":["def readLangs(lang1, lang2, reverse=False):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines = open('/content/drive/My Drive/Colab Notebooks/eng_rus_seq2seq_attention/%s_%s.txt' % (lang1, lang2), encoding='utf-8').\\\n","        read().strip().split('\\n')\n","\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(lang2)\n","        output_lang = Lang(lang1)\n","    else:\n","        input_lang = Lang(lang1)\n","        output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBOwgEBdM9uB"},"source":["MAX_LENGTH = 10\n","\n","eng_prefixes = (\n","    \"i am \", \"i m \",\n","    \"he is\", \"he s \",\n","    \"she is\", \"she s\",\n","    \"you are\", \"you re \",\n","    \"we are\", \"we re \",\n","    \"they are\", \"they re \"\n",")\n","\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH and \\\n","        p[1].startswith(eng_prefixes)\n","\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dZOGjd5M9uE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615313199555,"user_tz":-180,"elapsed":18019,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"12f1051c-9c5c-4206-b867-a2e0ad4dfac7"},"source":["def prepareData(lang1, lang2, reverse=False):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","\n","input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n","print(random.choice(pairs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading lines...\n","Read 421765 sentence pairs\n","Trimmed to 24897 sentence pairs\n","Counting words...\n","Counted words:\n","rus 9420\n","eng 4065\n","['это ты нанял тома .', 'you re the one who hired tom .']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vgtWqznCM9uH"},"source":["The Encoder\n","-----------\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"m9vm9QBWM9uI"},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FwLTlgSyM9uK"},"source":["The Decoder (лекционный), не использую.\n","-----------\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"PFbuUL1LM9uL"},"source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Evtc6GoD_mu"},"source":["# The Decoder_Attention (на основе скалярного произведения)."]},{"cell_type":"code","metadata":{"id":"QUPcFtiJD-Fa"},"source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1,\n","                 max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length + 2\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        weights = []\n","        for i in range(len(encoder_outputs)):\n","            weights.append(\n","                torch.div(torch.matmul(hidden[0][0], encoder_outputs[i]),\n","                          torch.sqrt(\n","                              torch.tensor(self.max_length, dtype=torch.float,\n","                                           device=device))\n","                          )\n","                )\n","        attn_weights = F.softmax(torch.tensor(weights, device=device))\n","\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0).unsqueeze(0),\n","                                 encoder_outputs.view(1, -1, self.hidden_size)\n","                                 )\n","\n","        output = torch.cat((attn_applied[0], embedded[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6gGPtXFM9uQ"},"source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Fn8VDv8M9uS"},"source":["teacher_forcing_ratio = 0.5\n","\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKsdwPmSM9uU"},"source":["import time\n","import math\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_z_k5IiM9uX"},"source":["def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(pairs))\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","\n","        loss = train(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    showPlot(plot_losses)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0JXG-RzCM9uZ"},"source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Bxf45h6M9ud"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            decoder_attentions[di] = decoder_attention.data\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di + 1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1qUmQIGwM9uf"},"source":["def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_56t10oM9uh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615234825735,"user_tz":-180,"elapsed":7097380,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"83259c2d-421e-4629-9d75-511e8fb3d64c"},"source":["hidden_size = 256\n","encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["7m 2s (- 98m 29s) (5000 6%) 3.0729\n","16m 15s (- 105m 41s) (10000 13%) 2.5422\n","24m 19s (- 97m 16s) (15000 20%) 2.2613\n","31m 43s (- 87m 15s) (20000 26%) 2.0680\n","39m 31s (- 79m 3s) (25000 33%) 1.8895\n","47m 25s (- 71m 8s) (30000 40%) 1.7468\n","57m 9s (- 65m 19s) (35000 46%) 1.6594\n","64m 33s (- 56m 29s) (40000 53%) 1.5606\n","71m 51s (- 47m 54s) (45000 60%) 1.4519\n","79m 54s (- 39m 57s) (50000 66%) 1.3673\n","87m 49s (- 31m 56s) (55000 73%) 1.2933\n","95m 45s (- 23m 56s) (60000 80%) 1.2374\n","103m 18s (- 15m 53s) (65000 86%) 1.1997\n","110m 46s (- 7m 54s) (70000 93%) 1.1503\n","118m 19s (- 0m 0s) (75000 100%) 1.1052\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xEoEylSyM9uj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615234850129,"user_tz":-180,"elapsed":550,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"0893739c-4320-462e-f00e-9703830688b5"},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["> я собираюсь навестить друга .\n","= i m going to visit a friend .\n","< i m going to study my friend . <EOS>\n","\n","> он все время читает .\n","= he is always reading .\n","< he is always reading reading . <EOS>\n","\n","> мы не остаемся .\n","= we re not staying .\n","< we re not . <EOS>\n","\n","> вы такои красивыи .\n","= you re so handsome .\n","< you re so handsome . <EOS>\n","\n","> я собираюсь это доказать .\n","= i m going to prove it .\n","< i m going to do that . <EOS>\n","\n","> я на вас больше не работаю .\n","= i m not working for you anymore .\n","< i m working on you on you . <EOS>\n","\n","> он очень общителен .\n","= he is very sociable .\n","< he is very angry . <EOS>\n","\n","> ты разрушаешь мою жизнь .\n","= you re ruining my life .\n","< you re ruining my life . <EOS>\n","\n","> мы с тобои примерно одного возраста .\n","= i m about your age .\n","< i am about your age . <EOS>\n","\n","> мне надоело притворяться .\n","= i m tired of pretending .\n","< i m tired of pretending . <EOS>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"hUeKs7K6gHIG","executionInfo":{"status":"ok","timestamp":1615235040023,"user_tz":-180,"elapsed":557,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"5fa056f9-7a2c-41a9-915d-60fed7a1005b"},"source":["df[0][4000]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'I loved you.'"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"4WxRIElOgva8","executionInfo":{"status":"ok","timestamp":1615235072911,"user_tz":-180,"elapsed":569,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"a85dafd4-fb42-4e39-deca-cd6ff00a8427"},"source":["df[1][4000]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Я Вас любил.'"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"jezDwNn6gIBs","executionInfo":{"status":"ok","timestamp":1615235456917,"user_tz":-180,"elapsed":526,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"c3f8c14a-6100-427f-d151-57531f19f366"},"source":["df[1][10000]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Я не мог пойти.'"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"vzc3k6D0qn9W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615235478522,"user_tz":-180,"elapsed":613,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"d3c770b2-e791-4949-cc88-d01c5b9da4d0"},"source":["output_words, attentions = evaluate(\n","    encoder1, attn_decoder1, \"я не мог уехать\")\n","plt.matshow(attentions.numpy())\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6fqVhe4yqpeY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615235546133,"user_tz":-180,"elapsed":649,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"96c55502-6477-487c-91a8-452998b84ac4"},"source":["def showAttention(input_sentence, output_words, attentions):\n","    # Set up figure with colorbar\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(attentions.numpy(), cmap='bone')\n","    fig.colorbar(cax)\n","\n","    # Set up axes\n","    ax.set_xticklabels([''] + input_sentence.split(' ') +\n","                       ['<EOS>'], rotation=90)\n","    ax.set_yticklabels([''] + output_words)\n","\n","    # Show label at every tick\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","\n","\n","def evaluateAndShowAttention(input_sentence):\n","    output_words, attentions = evaluate(\n","        encoder1, attn_decoder1, input_sentence)\n","    print('input =', input_sentence)\n","    print('output =', ' '.join(output_words))\n","    showAttention(input_sentence, output_words, attentions)\n","\n","\n","evaluateAndShowAttention(\"я вас\")\n","\n","evaluateAndShowAttention(\"я не мог уехать\")\n","\n","#evaluateAndShowAttention(\"я вас\")\n","\n","#evaluateAndShowAttention(\"я вас\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["input = я вас\n","output = i m firing you . <EOS>\n","input = я не мог уехать\n","output = i m not surprised . <EOS>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WcoNw3Tzqs8q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ukb-KHMZIGEk"},"source":["# The Decoder_Attention (на основе MLP)"]},{"cell_type":"markdown","metadata":{"id":"tvzVXc9ei6wp"},"source":["Поменяем class(основу класса на MLP)"]},{"cell_type":"code","metadata":{"id":"HWtQc4IHIswC"},"source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.attn = nn.Linear(self.hidden_size * 2, 1)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        weights = []\n","        for i in range(len(encoder_outputs)):\n","            weights.append(\n","                torch.tanh(self.attn(torch.cat((hidden[0][0],\n","                                                encoder_outputs[i]))))\n","                )\n","        attn_weights = F.softmax(torch.tensor(weights, device=device))\n","\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0).unsqueeze(0),\n","                                 encoder_outputs.view(1, -1, self.hidden_size)\n","                                 )\n","\n","        output = torch.cat((attn_applied[0], embedded[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NR53kmJOJAyT","executionInfo":{"status":"ok","timestamp":1615315599812,"user_tz":-180,"elapsed":2316098,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"37e6ba43-f605-4454-8361-0433b5692a15"},"source":["hidden_size = 256\n","encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n"," \n","trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["2m 34s (- 35m 59s) (5000 6%) 3.0506\n","5m 7s (- 33m 18s) (10000 13%) 2.5770\n","7m 39s (- 30m 39s) (15000 20%) 2.3280\n","10m 14s (- 28m 10s) (20000 26%) 2.1058\n","12m 49s (- 25m 39s) (25000 33%) 1.9320\n","15m 25s (- 23m 8s) (30000 40%) 1.8307\n","17m 58s (- 20m 32s) (35000 46%) 1.6805\n","20m 32s (- 17m 58s) (40000 53%) 1.5921\n","23m 4s (- 15m 23s) (45000 60%) 1.5306\n","25m 40s (- 12m 50s) (50000 66%) 1.4294\n","28m 12s (- 10m 15s) (55000 73%) 1.3363\n","30m 43s (- 7m 40s) (60000 80%) 1.3019\n","33m 17s (- 5m 7s) (65000 86%) 1.2601\n","35m 51s (- 2m 33s) (70000 93%) 1.1949\n","38m 24s (- 0m 0s) (75000 100%) 1.1265\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sthAA1eGJa3J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615315701940,"user_tz":-180,"elapsed":1509,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"f35c141a-cfca-4319-f0cd-3c6d94e5f0dd"},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["> я теперь замужем .\n","= i m now married .\n","< i m married now . <EOS>\n","\n","> ты становишься старше .\n","= you re getting older .\n","< you re getting older . <EOS>\n","\n","> ты не идеален .\n","= you re not perfect .\n","< you aren t perfect . <EOS>\n","\n","> он чрезвычаино чувствителен .\n","= he is very sensitive .\n","< he is an sensitive . <EOS>\n","\n","> на следующеи неделе у меня отпуск .\n","= i m going on vacation next week .\n","< i m on on vacation next week . <EOS>\n","\n","> я знаю об этом факте .\n","= i am aware of the fact .\n","< i m aware of of it . <EOS>\n","\n","> прости . я забыл .\n","= i m sorry . i forgot .\n","< i m sorry i forgot . <EOS>\n","\n","> мы двоюродные брат и сестра .\n","= we are cousins .\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["< we re cousins . <EOS>\n","\n","> я не сравниваю тома с мэри .\n","= i m not comparing tom to mary .\n","< i m not tom to tom tom . . <EOS>\n","\n","> я очень боюсь собак .\n","= i m very afraid of dogs .\n","< i m very afraid of dogs . <EOS>\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZahyGFdEJbmq"},"source":[""],"execution_count":null,"outputs":[]}]}
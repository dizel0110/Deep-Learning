{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:19:19.017474Z",
     "start_time": "2019-11-18T16:19:18.970512Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision as tv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:20:20.881570Z",
     "start_time": "2019-11-18T16:20:20.802160Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_dataset = tv.datasets.MNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.MNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:20:21.306023Z",
     "start_time": "2019-11-18T16:20:21.293827Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = torch.Tensor([0]), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:20:21.693926Z",
     "start_time": "2019-11-18T16:20:21.678441Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:20:22.749954Z",
     "start_time": "2019-11-18T16:20:22.740638Z"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5),\n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(400, 120),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:20:28.809141Z",
     "start_time": "2019-11-18T16:20:23.333771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 0.113. Train acc: 0.117. Train Loss: 589.539\n",
      "Step. time since epoch: 0.187. Train acc: 0.133. Train Loss: 43471.098\n",
      "Step. time since epoch: 0.297. Train acc: 0.094. Train Loss: 93349.023\n",
      "Step. time since epoch: 0.452. Train acc: 0.156. Train Loss: 48749.699\n",
      "Step. time since epoch: 0.621. Train acc: 0.133. Train Loss: 41218.789\n",
      "Step. time since epoch: 0.797. Train acc: 0.078. Train Loss: 47300.453\n",
      "Step. time since epoch: 0.967. Train acc: 0.062. Train Loss: 62516.086\n",
      "Step. time since epoch: 1.152. Train acc: 0.117. Train Loss: 34516.039\n",
      "Step. time since epoch: 1.317. Train acc: 0.094. Train Loss: 36430.434\n",
      "Step. time since epoch: 1.501. Train acc: 0.082. Train Loss: 41685.742\n",
      "Step. time since epoch: 1.726. Train acc: 0.113. Train Loss: 32121.875\n",
      "Step. time since epoch: 1.903. Train acc: 0.105. Train Loss: 18555.381\n",
      "Step. time since epoch: 2.086. Train acc: 0.086. Train Loss: 13596.615\n",
      "Step. time since epoch: 2.261. Train acc: 0.094. Train Loss: 21109.389\n",
      "Step. time since epoch: 2.447. Train acc: 0.102. Train Loss: 24144.027\n",
      "Step. time since epoch: 2.622. Train acc: 0.121. Train Loss: 23438.695\n",
      "Step. time since epoch: 2.802. Train acc: 0.113. Train Loss: 24767.332\n",
      "Step. time since epoch: 2.975. Train acc: 0.082. Train Loss: 25348.625\n",
      "Step. time since epoch: 3.148. Train acc: 0.105. Train Loss: 25658.600\n",
      "Step. time since epoch: 3.319. Train acc: 0.086. Train Loss: 28781.486\n",
      "Step. time since epoch: 3.487. Train acc: 0.105. Train Loss: 31992.234\n",
      "Step. time since epoch: 3.653. Train acc: 0.094. Train Loss: 18366.672\n",
      "Step. time since epoch: 3.826. Train acc: 0.125. Train Loss: 20914.479\n",
      "Step. time since epoch: 3.999. Train acc: 0.105. Train Loss: 25734.867\n",
      "Step. time since epoch: 4.185. Train acc: 0.098. Train Loss: 31045.645\n",
      "Step. time since epoch: 4.368. Train acc: 0.090. Train Loss: 27148.748\n",
      "Step. time since epoch: 4.548. Train acc: 0.109. Train Loss: 15622.396\n",
      "Step. time since epoch: 4.723. Train acc: 0.090. Train Loss: 16229.495\n",
      "Step. time since epoch: 4.915. Train acc: 0.098. Train Loss: 21202.529\n",
      "Step. time since epoch: 5.094. Train acc: 0.082. Train Loss: 24895.334\n",
      "Step. time since epoch: 5.281. Train acc: 0.082. Train Loss: 19639.213\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-3623842b82ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-204-c3bd730eccb6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, trainer, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtrain_l_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.9, 5\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:24:00.569981Z",
     "start_time": "2019-11-18T16:24:00.510393Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "transoforms = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((224,224)),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "train_dataset = tv.datasets.MNIST('.', train=True, transform=transoforms, download=True)\n",
    "test_dataset = tv.datasets.MNIST('.', train=False, transform=transoforms, download=True)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:24:01.253461Z",
     "start_time": "2019-11-18T16:24:01.005372Z"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(6400, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:24:45.386340Z",
     "start_time": "2019-11-18T16:24:01.447105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1.274. Train acc: 0.062. Train Loss: 73.765\n",
      "Step. time since epoch: 2.632. Train acc: 0.094. Train Loss: 73.716\n",
      "Step. time since epoch: 4.009. Train acc: 0.094. Train Loss: 73.571\n",
      "Step. time since epoch: 5.340. Train acc: 0.156. Train Loss: 73.444\n",
      "Step. time since epoch: 6.676. Train acc: 0.125. Train Loss: 73.762\n",
      "Step. time since epoch: 8.093. Train acc: 0.094. Train Loss: 74.187\n",
      "Step. time since epoch: 9.931. Train acc: 0.156. Train Loss: 73.346\n",
      "Step. time since epoch: 11.348. Train acc: 0.125. Train Loss: 73.533\n",
      "Step. time since epoch: 12.698. Train acc: 0.094. Train Loss: 74.027\n",
      "Step. time since epoch: 14.050. Train acc: 0.125. Train Loss: 73.601\n",
      "Step. time since epoch: 15.410. Train acc: 0.062. Train Loss: 73.721\n",
      "Step. time since epoch: 16.954. Train acc: 0.156. Train Loss: 73.202\n",
      "Step. time since epoch: 18.434. Train acc: 0.156. Train Loss: 73.674\n",
      "Step. time since epoch: 19.783. Train acc: 0.094. Train Loss: 73.774\n",
      "Step. time since epoch: 21.135. Train acc: 0.188. Train Loss: 73.411\n",
      "Step. time since epoch: 22.762. Train acc: 0.188. Train Loss: 73.687\n",
      "Step. time since epoch: 24.202. Train acc: 0.094. Train Loss: 74.290\n",
      "Step. time since epoch: 25.569. Train acc: 0.156. Train Loss: 73.536\n",
      "Step. time since epoch: 26.931. Train acc: 0.094. Train Loss: 73.820\n",
      "Step. time since epoch: 28.324. Train acc: 0.125. Train Loss: 73.661\n",
      "Step. time since epoch: 29.683. Train acc: 0.062. Train Loss: 73.874\n",
      "Step. time since epoch: 31.077. Train acc: 0.125. Train Loss: 73.369\n",
      "Step. time since epoch: 32.606. Train acc: 0.062. Train Loss: 73.981\n",
      "Step. time since epoch: 33.959. Train acc: 0.094. Train Loss: 74.415\n",
      "Step. time since epoch: 35.402. Train acc: 0.094. Train Loss: 73.861\n",
      "Step. time since epoch: 36.721. Train acc: 0.062. Train Loss: 73.566\n",
      "Step. time since epoch: 38.177. Train acc: 0.094. Train Loss: 74.224\n",
      "Step. time since epoch: 39.604. Train acc: 0.156. Train Loss: 73.681\n",
      "Step. time since epoch: 40.968. Train acc: 0.219. Train Loss: 73.472\n",
      "Step. time since epoch: 42.409. Train acc: 0.250. Train Loss: 73.049\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-d6885ecf20c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-204-c3bd730eccb6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, trainer, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtrain_l_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs  = 0.01, 5\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:33:15.808035Z",
     "start_time": "2019-11-18T16:33:15.795879Z"
    }
   },
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, input_channels, num_channels):\n",
    "    blk = nn.Sequential(nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1), nn.ReLU())\n",
    "    for i in range(num_convs - 1):\n",
    "        blk.add_module(\"conv{}\".format(i), nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1))\n",
    "        blk.add_module(\"relu{}\".format(i), nn.ReLU())\n",
    "    blk.add_module(\"pool\", nn.MaxPool2d(2, stride=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:35:30.287348Z",
     "start_time": "2019-11-18T16:35:30.283452Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_arch = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:39:16.358809Z",
     "start_time": "2019-11-18T16:39:16.040029Z"
    }
   },
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    net = nn.Sequential()\n",
    "\n",
    "    for i, (num_convs, input_ch, num_channels) in enumerate(conv_arch):\n",
    "        net.add_module(\"block{}\".format(i), vgg_block(num_convs, input_ch, num_channels))\n",
    "\n",
    "    \n",
    "    classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(6272, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10))\n",
    "\n",
    "    net.add_module('classifier', classifier)\n",
    "    return net\n",
    "\n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:37:57.884604Z",
     "start_time": "2019-11-18T16:37:57.709439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") \t\t torch.Size([1, 64, 112, 112])\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") \t\t torch.Size([1, 128, 56, 56])\n",
      "Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (conv0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu0): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") \t\t torch.Size([1, 256, 28, 28])\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (conv0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu0): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") \t\t torch.Size([1, 512, 14, 14])\n",
      "Sequential(\n",
      "  (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (conv0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu0): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") \t\t torch.Size([1, 512, 7, 7])\n",
      "Sequential(\n",
      "  (0): Flatten()\n",
      "  (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Dropout(p=0.5, inplace=False)\n",
      "  (7): Linear(in_features=4096, out_features=10, bias=True)\n",
      ") \t\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x = train_dataset[0][0].reshape(1,1,224,224)\n",
    "for l in net:\n",
    "    x = l(x)\n",
    "    print(l, \"\\t\\t\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:39:32.280283Z",
     "start_time": "2019-11-18T16:39:31.939284Z"
    }
   },
   "outputs": [],
   "source": [
    "ratio = 4\n",
    "small_conv_arch = [(v[0], max(v[1] // ratio, 1), v[2] // ratio) for v in conv_arch]\n",
    "net = vgg(small_conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:39:50.898401Z",
     "start_time": "2019-11-18T16:39:50.894050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 16), (1, 16, 32), (2, 32, 64), (2, 64, 128), (2, 128, 128)]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_conv_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:39:42.227529Z",
     "start_time": "2019-11-18T16:39:42.078156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") \t\t torch.Size([1, 16, 112, 112])\n",
      "Sequential(\n",
      "  (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") \t\t torch.Size([1, 32, 56, 56])\n",
      "Sequential(\n",
      "  (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (conv0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu0): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") \t\t torch.Size([1, 64, 28, 28])\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (conv0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu0): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") \t\t torch.Size([1, 128, 14, 14])\n",
      "Sequential(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (conv0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu0): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ") \t\t torch.Size([1, 128, 7, 7])\n",
      "Sequential(\n",
      "  (0): Flatten()\n",
      "  (1): Linear(in_features=6272, out_features=4096, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Dropout(p=0.5, inplace=False)\n",
      "  (7): Linear(in_features=4096, out_features=10, bias=True)\n",
      ") \t\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x = train_dataset[0][0].reshape(1,1,224,224)\n",
    "for l in net:\n",
    "    x = l(x)\n",
    "    print(l, \"\\t\\t\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:41:08.457065Z",
     "start_time": "2019-11-18T16:40:17.572925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1.560. Train acc: 0.125. Train Loss: 73.637\n",
      "Step. time since epoch: 3.241. Train acc: 0.062. Train Loss: 74.438\n",
      "Step. time since epoch: 4.870. Train acc: 0.062. Train Loss: 73.409\n",
      "Step. time since epoch: 6.491. Train acc: 0.156. Train Loss: 72.695\n",
      "Step. time since epoch: 8.070. Train acc: 0.094. Train Loss: 75.087\n",
      "Step. time since epoch: 9.722. Train acc: 0.094. Train Loss: 75.459\n",
      "Step. time since epoch: 11.380. Train acc: 0.156. Train Loss: 73.588\n",
      "Step. time since epoch: 13.005. Train acc: 0.125. Train Loss: 73.655\n",
      "Step. time since epoch: 14.631. Train acc: 0.031. Train Loss: 75.266\n",
      "Step. time since epoch: 16.259. Train acc: 0.125. Train Loss: 74.057\n",
      "Step. time since epoch: 17.910. Train acc: 0.062. Train Loss: 73.834\n",
      "Step. time since epoch: 19.556. Train acc: 0.125. Train Loss: 72.412\n",
      "Step. time since epoch: 21.268. Train acc: 0.125. Train Loss: 73.535\n",
      "Step. time since epoch: 22.961. Train acc: 0.062. Train Loss: 74.912\n",
      "Step. time since epoch: 24.577. Train acc: 0.062. Train Loss: 74.088\n",
      "Step. time since epoch: 26.202. Train acc: 0.188. Train Loss: 74.167\n",
      "Step. time since epoch: 27.884. Train acc: 0.094. Train Loss: 74.714\n",
      "Step. time since epoch: 29.550. Train acc: 0.156. Train Loss: 74.135\n",
      "Step. time since epoch: 31.237. Train acc: 0.094. Train Loss: 75.629\n",
      "Step. time since epoch: 32.901. Train acc: 0.125. Train Loss: 74.139\n",
      "Step. time since epoch: 34.574. Train acc: 0.062. Train Loss: 75.008\n",
      "Step. time since epoch: 36.238. Train acc: 0.094. Train Loss: 73.546\n",
      "Step. time since epoch: 38.000. Train acc: 0.125. Train Loss: 74.407\n",
      "Step. time since epoch: 39.825. Train acc: 0.000. Train Loss: 75.441\n",
      "Step. time since epoch: 41.494. Train acc: 0.031. Train Loss: 73.589\n",
      "Step. time since epoch: 43.165. Train acc: 0.094. Train Loss: 73.947\n",
      "Step. time since epoch: 44.824. Train acc: 0.000. Train Loss: 76.190\n",
      "Step. time since epoch: 46.505. Train acc: 0.094. Train Loss: 74.089\n",
      "Step. time since epoch: 48.538. Train acc: 0.125. Train Loss: 73.465\n",
      "Step. time since epoch: 50.280. Train acc: 0.250. Train Loss: 73.322\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-242-a49e7d36726a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-204-c3bd730eccb6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, trainer, num_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.05, 5\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NiN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:55:01.945030Z",
     "start_time": "2019-11-18T16:55:01.937207Z"
    }
   },
   "outputs": [],
   "source": [
    "def nin_block(input_channels, num_channels, kernel_size, strides, padding):\n",
    "    blk = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, num_channels, kernel_size, strides, padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(num_channels, num_channels, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(num_channels, num_channels, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "    )\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:55:56.351798Z",
     "start_time": "2019-11-18T16:55:56.323655Z"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(nin_block(1, 96, kernel_size=11, strides=4, padding=0),\n",
    "        nn.MaxPool2d(3, stride=2),\n",
    "        nin_block(96, 256, kernel_size=5, strides=1, padding=2),\n",
    "        nn.MaxPool2d(3, stride=2),\n",
    "        nin_block(256, 384, kernel_size=3, strides=1, padding=1),\n",
    "        nn.MaxPool2d(3, stride=2),\n",
    "        nn.Dropout(0.5),\n",
    "        nin_block(384, 10, kernel_size=3, strides=1, padding=1),\n",
    "        nn.AvgPool2d(5),\n",
    "        nn.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:55:58.680514Z",
     "start_time": "2019-11-18T16:55:58.637248Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      ") torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([1, 96, 26, 26])\n",
      "Sequential(\n",
      "  (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      ") torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([1, 256, 12, 12])\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      ") torch.Size([1, 384, 12, 12])\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([1, 384, 5, 5])\n",
      "Dropout(p=0.5, inplace=False) torch.Size([1, 384, 5, 5])\n",
      "Sequential(\n",
      "  (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      ") torch.Size([1, 10, 5, 5])\n",
      "AvgPool2d(kernel_size=5, stride=5, padding=0) torch.Size([1, 10, 1, 1])\n",
      "Flatten() torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = train_dataset[0][0].reshape(1, 1, 224, 224)\n",
    "for l in net:\n",
    "    X = l(X)\n",
    "    print(l , X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T16:56:41.832949Z",
     "start_time": "2019-11-18T16:56:01.052982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1.431. Train acc: 0.125. Train Loss: 73.553\n",
      "Step. time since epoch: 2.855. Train acc: 0.000. Train Loss: 74.795\n",
      "Step. time since epoch: 4.325. Train acc: 0.094. Train Loss: 73.754\n",
      "Step. time since epoch: 5.811. Train acc: 0.062. Train Loss: 73.803\n",
      "Step. time since epoch: 7.281. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 8.734. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 10.173. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 11.608. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 13.079. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 14.502. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 15.989. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 17.537. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 18.994. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 20.437. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 21.849. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 23.349. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 24.788. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 26.229. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 27.747. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 29.447. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 30.927. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 32.657. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 34.520. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 36.144. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 37.625. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 39.176. Train acc: 0.188. Train Loss: 73.683\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-a49e7d36726a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-204-c3bd730eccb6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, trainer, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtrain_l_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.05, 5\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogleLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:08:12.092643Z",
     "start_time": "2019-11-18T17:08:12.087776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.module.Module"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T13:29:01.329069Z",
     "start_time": "2019-11-17T13:29:01.317911Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, ic, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        self.p1_1 = nn.Sequential(nn.Conv2d(ic, c1, kernel_size=1), nn.ReLU())\n",
    "        self.p2_1 = nn.Sequential(nn.Conv2d(ic, c2[0], kernel_size=1), nn.ReLU())\n",
    "        self.p2_2 = nn.Sequential(nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1), nn.ReLU())\n",
    "        self.p3_1 = nn.Sequential(nn.Conv2d(ic, c3[0], kernel_size=1), nn.ReLU())\n",
    "        self.p3_2 = nn.Sequential(nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2), nn.ReLU())\n",
    "        self.p4_1 = nn.Sequential(nn.MaxPool2d(3, stride=1, padding=1))\n",
    "        self.p4_2 = nn.Sequential(nn.Conv2d(ic, c4, kernel_size=1), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = self.p1_1(x)\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # Concatenate the outputs on the channel dimension.\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T13:29:01.480962Z",
     "start_time": "2019-11-17T13:29:01.476713Z"
    }
   },
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.ReLU(),\n",
    "       nn.MaxPool2d(3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T13:29:01.626101Z",
     "start_time": "2019-11-17T13:29:01.620836Z"
    }
   },
   "outputs": [],
   "source": [
    "b2 = nn.Sequential(\n",
    "       nn.Conv2d(64, 64, kernel_size=1),\n",
    "       nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "       nn.MaxPool2d(3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T13:30:56.752212Z",
     "start_time": "2019-11-17T13:30:56.741605Z"
    }
   },
   "outputs": [],
   "source": [
    "b3 = nn.Sequential(\n",
    "       Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "       Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "       nn.MaxPool2d(3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T13:34:33.986895Z",
     "start_time": "2019-11-17T13:34:33.949995Z"
    }
   },
   "outputs": [],
   "source": [
    "b4 = nn.Sequential(\n",
    "       Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "       Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "       Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "       Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "       Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "       nn.MaxPool2d(3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T13:34:49.151063Z",
     "start_time": "2019-11-17T13:34:49.120596Z"
    }
   },
   "outputs": [],
   "source": [
    "b5 = nn.Sequential(\n",
    "       Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "       Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "       nn.AvgPool2d(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T13:35:35.796920Z",
     "start_time": "2019-11-17T13:35:35.792707Z"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(b1, b2, b3, b4, b5, nn.Flatten(), nn.Linear(1024, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:11:01.447938Z",
     "start_time": "2019-11-18T17:11:01.372789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      ") torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([1, 96, 26, 26])\n",
      "Sequential(\n",
      "  (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      ") torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([1, 256, 12, 12])\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      ") torch.Size([1, 384, 12, 12])\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([1, 384, 5, 5])\n",
      "Dropout(p=0.5, inplace=False) torch.Size([1, 384, 5, 5])\n",
      "Sequential(\n",
      "  (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      ") torch.Size([1, 10, 5, 5])\n",
      "AvgPool2d(kernel_size=5, stride=5, padding=0) torch.Size([1, 10, 1, 1])\n",
      "Flatten() torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = train_dataset[0][0].reshape(1, 1, 224, 224)\n",
    "for l in net:\n",
    "    X = l(X)\n",
    "    print(l , X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:21:23.003367Z",
     "start_time": "2019-11-18T17:11:07.846611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1.408. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 2.805. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 4.202. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 5.615. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 7.018. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 8.427. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 9.838. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 11.256. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 12.660. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 14.102. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 15.511. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 16.935. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 18.384. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 20.253. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 21.717. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 23.173. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 24.782. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 26.470. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 27.993. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 29.737. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 31.519. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 33.513. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 34.998. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 36.510. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 38.462. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 40.164. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 41.765. Train acc: 0.000. Train Loss: 73.683\n",
      "Step. time since epoch: 43.332. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 44.720. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 46.222. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 47.864. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 49.412. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 50.871. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 52.297. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 53.858. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 55.270. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 56.723. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 58.170. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 59.588. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 61.092. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 62.668. Train acc: 0.219. Train Loss: 73.683\n",
      "Step. time since epoch: 64.040. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 65.549. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 67.023. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 68.594. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 70.028. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 71.440. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 72.851. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 74.290. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 75.845. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 77.250. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 78.635. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 80.033. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 81.421. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 82.819. Train acc: 0.281. Train Loss: 73.683\n",
      "Step. time since epoch: 84.196. Train acc: 0.000. Train Loss: 73.683\n",
      "Step. time since epoch: 85.567. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 86.959. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 88.411. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 89.837. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 91.273. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 92.713. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 94.134. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 95.510. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 96.987. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 98.377. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 99.793. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 101.200. Train acc: 0.000. Train Loss: 73.683\n",
      "Step. time since epoch: 102.597. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 104.101. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 105.492. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 106.881. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 108.277. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 109.682. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 111.080. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 112.495. Train acc: 0.000. Train Loss: 73.683\n",
      "Step. time since epoch: 113.918. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 115.317. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 116.714. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 118.106. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 119.527. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 120.942. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 122.342. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 123.740. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 125.118. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 126.493. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 127.887. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 129.279. Train acc: 0.219. Train Loss: 73.683\n",
      "Step. time since epoch: 130.672. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 132.083. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 133.502. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 134.888. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 136.275. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 137.667. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 139.059. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 140.459. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 141.869. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 143.269. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 144.695. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 146.076. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 147.487. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 148.900. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 150.315. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 151.809. Train acc: 0.219. Train Loss: 73.683\n",
      "Step. time since epoch: 153.220. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 154.627. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 156.001. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 157.382. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 158.772. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 160.161. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 161.601. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 163.004. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 164.419. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 165.810. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 167.193. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 168.594. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 169.991. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 171.446. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 172.879. Train acc: 0.188. Train Loss: 73.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 174.299. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 175.684. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 177.241. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 178.764. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 180.271. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 181.808. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 183.362. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 184.885. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 186.377. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 187.818. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 189.295. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 190.850. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 192.392. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 193.795. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 195.192. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 196.561. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 197.944. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 199.437. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 200.955. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 202.554. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 204.433. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 205.821. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 207.187. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 208.570. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 209.985. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 211.399. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 212.927. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 214.360. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 215.761. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 217.186. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 218.570. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 219.938. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 221.434. Train acc: 0.000. Train Loss: 73.683\n",
      "Step. time since epoch: 222.860. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 224.239. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 225.635. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 227.024. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 228.396. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 229.771. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 231.159. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 232.584. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 233.976. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 235.380. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 237.185. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 238.669. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 240.117. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 241.520. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 242.937. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 244.352. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 245.752. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 247.237. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 248.631. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 249.992. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 251.368. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 252.773. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 254.170. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 255.574. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 257.008. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 258.471. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 259.897. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 261.398. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 262.866. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 264.311. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 265.773. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 267.281. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 268.810. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 270.283. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 271.798. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 273.316. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 274.921. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 276.443. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 277.952. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 279.412. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 280.925. Train acc: 0.250. Train Loss: 73.683\n",
      "Step. time since epoch: 282.403. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 283.881. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 285.473. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 287.011. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 288.517. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 289.962. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 291.484. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 293.011. Train acc: 0.000. Train Loss: 73.683\n",
      "Step. time since epoch: 294.397. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 295.839. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 297.561. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 299.111. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 300.588. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 302.134. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 303.739. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 305.177. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 306.645. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 308.062. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 309.419. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 310.874. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 312.356. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 313.747. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 315.122. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 316.509. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 317.932. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 319.314. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 320.684. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 322.053. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 323.424. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 324.889. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 326.254. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 327.632. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 329.009. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 330.388. Train acc: 0.250. Train Loss: 73.683\n",
      "Step. time since epoch: 331.898. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 333.317. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 334.728. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 336.191. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 337.699. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 339.071. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 340.512. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 341.947. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 343.389. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 344.898. Train acc: 0.000. Train Loss: 73.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 346.417. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 347.953. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 349.409. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 350.878. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 352.335. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 353.776. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 355.199. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 356.604. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 357.983. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 359.372. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 360.766. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 362.135. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 363.578. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 365.045. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 366.498. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 367.953. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 369.349. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 370.754. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 372.122. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 373.585. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 375.053. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 376.518. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 377.951. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 379.406. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 380.933. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 382.411. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 383.893. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 385.353. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 386.848. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 388.315. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 389.778. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 391.281. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 392.689. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 394.063. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 395.473. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 396.876. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 398.346. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 399.866. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 401.326. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 402.832. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 404.291. Train acc: 0.000. Train Loss: 73.683\n",
      "Step. time since epoch: 405.842. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 407.358. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 408.864. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 410.313. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 411.731. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 413.176. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 414.607. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 416.044. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 417.501. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 418.913. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 420.351. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 421.802. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 423.238. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 424.662. Train acc: 0.000. Train Loss: 73.683\n",
      "Step. time since epoch: 426.090. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 427.523. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 428.970. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 430.466. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 431.924. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 433.318. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 434.680. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 436.064. Train acc: 0.000. Train Loss: 73.683\n",
      "Step. time since epoch: 437.449. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 438.838. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 440.239. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 441.634. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 443.022. Train acc: 0.219. Train Loss: 73.683\n",
      "Step. time since epoch: 444.404. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 445.773. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 447.147. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 448.521. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 449.903. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 451.303. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 452.713. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 454.067. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 455.531. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 456.942. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 458.338. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 459.746. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 461.195. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 462.886. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 464.358. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 465.807. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 467.191. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 468.575. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 469.996. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 471.380. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 472.837. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 474.351. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 475.836. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 477.205. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 478.587. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 480.017. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 481.495. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 482.928. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 484.401. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 485.948. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 487.434. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 488.960. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 490.494. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 492.055. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 493.555. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 494.960. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 496.334. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 497.812. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 499.238. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 500.882. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 502.383. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 503.892. Train acc: 0.219. Train Loss: 73.683\n",
      "Step. time since epoch: 505.282. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 506.717. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 508.165. Train acc: 0.250. Train Loss: 73.683\n",
      "Step. time since epoch: 509.540. Train acc: 0.250. Train Loss: 73.683\n",
      "Step. time since epoch: 511.110. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 512.626. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 514.106. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 515.571. Train acc: 0.062. Train Loss: 73.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 517.000. Train acc: 0.219. Train Loss: 73.683\n",
      "Step. time since epoch: 518.474. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 519.945. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 521.345. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 522.804. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 524.242. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 525.701. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 527.078. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 528.537. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 529.948. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 531.349. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 532.787. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 534.271. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 535.706. Train acc: 0.000. Train Loss: 73.683\n",
      "Step. time since epoch: 537.159. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 538.581. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 539.993. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 541.493. Train acc: 0.281. Train Loss: 73.683\n",
      "Step. time since epoch: 543.203. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 544.765. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 547.012. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 548.637. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 550.203. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 551.732. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 553.961. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 555.359. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 556.741. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 558.102. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 559.477. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 560.857. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 562.219. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 563.591. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 564.971. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 566.339. Train acc: 0.250. Train Loss: 73.683\n",
      "Step. time since epoch: 567.688. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 569.031. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 570.400. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 571.776. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 573.157. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 574.524. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 575.900. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 577.286. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 578.639. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 580.004. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 581.622. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 583.273. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 584.948. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 586.317. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 587.683. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 589.034. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 590.393. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 591.779. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 593.182. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 594.611. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 595.989. Train acc: 0.188. Train Loss: 73.683\n",
      "Step. time since epoch: 597.365. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 598.723. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 600.355. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 601.848. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 603.226. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 604.673. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 606.182. Train acc: 0.062. Train Loss: 73.683\n",
      "Step. time since epoch: 607.613. Train acc: 0.156. Train Loss: 73.683\n",
      "Step. time since epoch: 609.010. Train acc: 0.031. Train Loss: 73.683\n",
      "Step. time since epoch: 610.461. Train acc: 0.250. Train Loss: 73.683\n",
      "Step. time since epoch: 611.881. Train acc: 0.125. Train Loss: 73.683\n",
      "Step. time since epoch: 613.428. Train acc: 0.094. Train Loss: 73.683\n",
      "Step. time since epoch: 614.925. Train acc: 0.062. Train Loss: 73.683\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-a49e7d36726a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-204-c3bd730eccb6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, trainer, num_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.05, 5\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:21:46.290923Z",
     "start_time": "2019-11-18T17:21:46.236514Z"
    }
   },
   "outputs": [],
   "source": [
    "transoforms = tv.transforms.Compose([\n",
    "    tv.transforms.Grayscale(3),\n",
    "    tv.transforms.Resize((224,224)),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "train_dataset = tv.datasets.MNIST('.', train=True, transform=transoforms, download=True)\n",
    "test_dataset = tv.datasets.MNIST('.', train=False, transform=transoforms, download=True)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:22:33.772924Z",
     "start_time": "2019-11-18T17:22:33.293818Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tv.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:23:47.319979Z",
     "start_time": "2019-11-18T17:23:47.316747Z"
    }
   },
   "outputs": [],
   "source": [
    "##   :\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:24:04.770976Z",
     "start_time": "2019-11-18T17:24:04.766810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:24:12.305790Z",
     "start_time": "2019-11-18T17:24:12.302517Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(in_features=512, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:24:42.228326Z",
     "start_time": "2019-11-18T17:24:42.222643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:25:11.558131Z",
     "start_time": "2019-11-18T17:25:11.554358Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:26:20.718099Z",
     "start_time": "2019-11-18T17:25:20.979097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 1.118. Train acc: 0.031. Train Loss: 77.998\n",
      "Step. time since epoch: 2.217. Train acc: 0.031. Train Loss: 81.995\n",
      "Step. time since epoch: 3.312. Train acc: 0.156. Train Loss: 72.565\n",
      "Step. time since epoch: 4.417. Train acc: 0.219. Train Loss: 69.465\n",
      "Step. time since epoch: 5.597. Train acc: 0.156. Train Loss: 73.562\n",
      "Step. time since epoch: 6.811. Train acc: 0.500. Train Loss: 55.271\n",
      "Step. time since epoch: 8.055. Train acc: 0.250. Train Loss: 69.794\n",
      "Step. time since epoch: 9.237. Train acc: 0.375. Train Loss: 53.511\n",
      "Step. time since epoch: 10.383. Train acc: 0.562. Train Loss: 35.115\n",
      "Step. time since epoch: 11.522. Train acc: 0.812. Train Loss: 19.998\n",
      "Step. time since epoch: 12.821. Train acc: 0.531. Train Loss: 41.876\n",
      "Step. time since epoch: 14.044. Train acc: 0.750. Train Loss: 23.873\n",
      "Step. time since epoch: 15.412. Train acc: 0.688. Train Loss: 30.894\n",
      "Step. time since epoch: 16.602. Train acc: 0.688. Train Loss: 30.866\n",
      "Step. time since epoch: 17.797. Train acc: 0.625. Train Loss: 25.660\n",
      "Step. time since epoch: 18.986. Train acc: 0.750. Train Loss: 32.290\n",
      "Step. time since epoch: 20.230. Train acc: 0.531. Train Loss: 39.788\n",
      "Step. time since epoch: 21.665. Train acc: 0.688. Train Loss: 54.263\n",
      "Step. time since epoch: 22.805. Train acc: 0.594. Train Loss: 50.563\n",
      "Step. time since epoch: 24.200. Train acc: 0.594. Train Loss: 43.609\n",
      "Step. time since epoch: 25.385. Train acc: 0.812. Train Loss: 21.192\n",
      "Step. time since epoch: 26.678. Train acc: 0.812. Train Loss: 14.588\n",
      "Step. time since epoch: 27.873. Train acc: 0.781. Train Loss: 26.192\n",
      "Step. time since epoch: 29.221. Train acc: 0.844. Train Loss: 18.921\n",
      "Step. time since epoch: 30.389. Train acc: 0.906. Train Loss: 13.792\n",
      "Step. time since epoch: 31.713. Train acc: 0.938. Train Loss: 10.510\n",
      "Step. time since epoch: 32.830. Train acc: 0.750. Train Loss: 26.937\n",
      "Step. time since epoch: 33.953. Train acc: 0.812. Train Loss: 13.720\n",
      "Step. time since epoch: 35.212. Train acc: 0.844. Train Loss: 21.720\n",
      "Step. time since epoch: 36.550. Train acc: 0.688. Train Loss: 29.462\n",
      "Step. time since epoch: 37.812. Train acc: 0.812. Train Loss: 19.671\n",
      "Step. time since epoch: 38.945. Train acc: 0.812. Train Loss: 16.279\n",
      "Step. time since epoch: 40.136. Train acc: 0.750. Train Loss: 24.268\n",
      "Step. time since epoch: 41.393. Train acc: 0.875. Train Loss: 12.106\n",
      "Step. time since epoch: 42.576. Train acc: 0.781. Train Loss: 18.211\n",
      "Step. time since epoch: 43.727. Train acc: 0.688. Train Loss: 36.606\n",
      "Step. time since epoch: 44.862. Train acc: 0.812. Train Loss: 19.289\n",
      "Step. time since epoch: 46.170. Train acc: 0.719. Train Loss: 19.584\n",
      "Step. time since epoch: 47.346. Train acc: 0.812. Train Loss: 16.104\n",
      "Step. time since epoch: 48.509. Train acc: 0.625. Train Loss: 40.490\n",
      "Step. time since epoch: 49.655. Train acc: 0.906. Train Loss: 13.347\n",
      "Step. time since epoch: 50.941. Train acc: 0.781. Train Loss: 23.584\n",
      "Step. time since epoch: 52.504. Train acc: 0.625. Train Loss: 43.865\n",
      "Step. time since epoch: 53.726. Train acc: 0.812. Train Loss: 19.787\n",
      "Step. time since epoch: 54.988. Train acc: 0.906. Train Loss: 5.606\n",
      "Step. time since epoch: 56.175. Train acc: 0.844. Train Loss: 17.813\n",
      "Step. time since epoch: 57.306. Train acc: 0.812. Train Loss: 18.551\n",
      "Step. time since epoch: 58.529. Train acc: 0.688. Train Loss: 33.482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-31e0e7d10abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-204-c3bd730eccb6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, trainer, num_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_iter, test_iter, trainer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

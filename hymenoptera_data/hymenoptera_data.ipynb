{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hymenoptera_data.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"16f6bec3dbc546e59e5922b3aec89088":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_33f4346dc1ba46d49f1bf3898bfc179c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ce2c5deed04a445d8335ff4ddb2372b0","IPY_MODEL_afa4ef656ee243fea0b379004e36989e"]}},"33f4346dc1ba46d49f1bf3898bfc179c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce2c5deed04a445d8335ff4ddb2372b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3556afe8fe1241a299931ee584c9592f","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":46827520,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":46827520,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d62cee62a7fc4c0fb46724bbacec4b06"}},"afa4ef656ee243fea0b379004e36989e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8ac88d5a635746d387429c4ff6e65b69","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 44.7M/44.7M [1:39:47&lt;00:00, 7.82kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8c8dd0f1db1a4c309420acebbf598657"}},"3556afe8fe1241a299931ee584c9592f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d62cee62a7fc4c0fb46724bbacec4b06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ac88d5a635746d387429c4ff6e65b69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8c8dd0f1db1a4c309420acebbf598657":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9bef0475445b4fadbbd9298ce161e953":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5f6535abb7c74669b9f1dbf3359c98cb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_071f105b4b514f058ee74322fbed281a","IPY_MODEL_350e2bb3726a4cbabe2ce1a271e19ced"]}},"5f6535abb7c74669b9f1dbf3359c98cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"071f105b4b514f058ee74322fbed281a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_baf6094168a54293be649e1ae8024492","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":553433881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":553433881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f10f21051eb042d09490a339e36a31a4"}},"350e2bb3726a4cbabe2ce1a271e19ced":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bfa4054e3ef14961b3ed6dc1ac3ad233","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528M/528M [00:49&lt;00:00, 11.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b7e5715cfc2a4df4858a1db20104282f"}},"baf6094168a54293be649e1ae8024492":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f10f21051eb042d09490a339e36a31a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bfa4054e3ef14961b3ed6dc1ac3ad233":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b7e5715cfc2a4df4858a1db20104282f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"428437bf7c664721a748b67637f21cc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4ac121f645bd4676a77400d0db460a8b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2f7cd2fa2ac047d8845b0adf8a25f2df","IPY_MODEL_ea0ac53f3d8341d7a8bd19651860c1ba"]}},"4ac121f645bd4676a77400d0db460a8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f7cd2fa2ac047d8845b0adf8a25f2df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_95082ec51eb54cb6982c40997a3d8761","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eedff8e203bf445c8528bbb8fa81a9a1"}},"ea0ac53f3d8341d7a8bd19651860c1ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dc7014fb2f22476b91255388c35448f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:01&lt;00:00, 9433346.67it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5ea9902fbb18431383ebe9814b9ac972"}},"95082ec51eb54cb6982c40997a3d8761":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"eedff8e203bf445c8528bbb8fa81a9a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc7014fb2f22476b91255388c35448f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5ea9902fbb18431383ebe9814b9ac972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c04f30f7df1647b49eaa80d8a322b358":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_adfe91a54641492bb4109c250d39a203","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_603f3576e0dd493ba0bb6fa8c44ed138","IPY_MODEL_cbae3e80765942a281efa415fa468a77"]}},"adfe91a54641492bb4109c250d39a203":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"603f3576e0dd493ba0bb6fa8c44ed138":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fa43819ea543420f9710f056b6a693bc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bcaead8ffa724ec4b308fbd4f3785546"}},"cbae3e80765942a281efa415fa468a77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_10bf2f74b8be4c90ad54faee547e1445","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:00&lt;00:00, 194683.49it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_55b15d60f6e54e72884436c4156aacf9"}},"fa43819ea543420f9710f056b6a693bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bcaead8ffa724ec4b308fbd4f3785546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"10bf2f74b8be4c90ad54faee547e1445":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"55b15d60f6e54e72884436c4156aacf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4950a587aff24cfcad29b7d938699618":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ee8e8066143c408bb1c6ee2d11c3f2ef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c47205eeb66e4ac5a617e4c6a09cc207","IPY_MODEL_ccb7ad8a2d494d93a2eab42152d9fc7d"]}},"ee8e8066143c408bb1c6ee2d11c3f2ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c47205eeb66e4ac5a617e4c6a09cc207":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e74ca2864f054ac1bac6409bf3414c5e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fca0da89983f4c81b0c1dee1bf4668c3"}},"ccb7ad8a2d494d93a2eab42152d9fc7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_36d4a2e6c862409c891dbb983d672fce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:18&lt;00:00, 1796207.68it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33b5fca0e4fc4dcbb1d643bed404c912"}},"e74ca2864f054ac1bac6409bf3414c5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fca0da89983f4c81b0c1dee1bf4668c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36d4a2e6c862409c891dbb983d672fce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"33b5fca0e4fc4dcbb1d643bed404c912":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f88dbc9647c4a2cb1eaf659c31e3687":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_13c3825417484f9193e0571d8f72cfbc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_590d7fd932fc4733adfc164eca3288f5","IPY_MODEL_30f20870495149b2894e34b017d6ce99"]}},"13c3825417484f9193e0571d8f72cfbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"590d7fd932fc4733adfc164eca3288f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a9dd7773ffd5416ab34afee60363815e","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a914d1b620d94d3494feade98af63000"}},"30f20870495149b2894e34b017d6ce99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aa17f5640a4a45fa8aaa76b50840cbe5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/4542 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe0daede8344411887d39b23140cc362"}},"a9dd7773ffd5416ab34afee60363815e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a914d1b620d94d3494feade98af63000":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa17f5640a4a45fa8aaa76b50840cbe5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe0daede8344411887d39b23140cc362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Sa0qBTJwzKeG"},"source":["# **Основное задание**\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"KLi1lZJJzUIW"},"source":["Возьмите датасет https://www.kaggle.com/ajayrana/hymenoptera-data/kernels\r\n","\r\n","1.Обучите на нем модели ResNet 18 и VGG 16 с нуля (5-10 эпох)  \r\n","2.Обучите на нем модели ResNet 18 и VGG 16 с использованием FineTuning (5-10 эпох)  \r\n","3.Добавьте аугментацию данных к пункту 2  \r\n","\r\n","Сравните качество всех 3 полученных подходов  \r\n","\r\n","Задание со звездочкой  \r\n","Примените FineTuning ResNet 18 к FashionMnist. Удалось ли увидеть резкое увеличение качества?  \r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"33rP1XXKeuYm"},"source":["# Загружаем библиотеки. Смотрим, что доступно cpu или cuda. Загружаем данные для пунктов 1. и 2. (модель обучаемая с нуля и модель предобученная (без аугментации)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAyHNSz03Ks4","executionInfo":{"status":"ok","timestamp":1615922956300,"user_tz":-180,"elapsed":27376,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"54159858-1078-499f-965f-e3ed9b11d3eb"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"21v9fScZjLo-","executionInfo":{"status":"ok","timestamp":1615922961100,"user_tz":-180,"elapsed":3409,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["import torch\r\n","from torch import nn\r\n","import torchvision.models as models\r\n","\r\n","import torchvision as tv\r\n","import time\r\n","\r\n","import os"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"GISwEoRNz7WG","executionInfo":{"status":"ok","timestamp":1615922963476,"user_tz":-180,"elapsed":678,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8MRb8_PJz7YJ","executionInfo":{"status":"ok","timestamp":1615922967046,"user_tz":-180,"elapsed":721,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"6f0ca1a1-d8e4-4ac9-94c7-f9c8623e2c9c"},"source":["dev"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"5u5w9Ygtz7o3","executionInfo":{"status":"ok","timestamp":1615922969466,"user_tz":-180,"elapsed":664,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["data_dir = '/content/drive/My Drive/Colab Notebooks/hymenoptera_data/'\r\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFp9L17x31Se","executionInfo":{"status":"ok","timestamp":1615922971412,"user_tz":-180,"elapsed":624,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["BATCH_SIZE = 32"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CuTybGEAz7qk","executionInfo":{"status":"ok","timestamp":1615922977071,"user_tz":-180,"elapsed":2898,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"6da45ec9-366d-403a-9560-73718ba1a99a"},"source":["# Data augmentation and normalization for training\r\n","# Just normalization for validation\r\n","data_transforms = {\r\n","    'train': tv.transforms.Compose([\r\n","#         tv.transforms.RandomResizedCrop(224),\r\n","#         tv.transforms.RandomHorizontalFlip(),\r\n","#         tv.transforms.RandomVerticalFlip(),\r\n","        tv.transforms.CenterCrop(224),\r\n","        tv.transforms.ToTensor(),\r\n","        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n","    ]),\r\n","    'val': tv.transforms.Compose([\r\n","        tv.transforms.Resize(256),\r\n","        tv.transforms.CenterCrop(224),\r\n","        tv.transforms.ToTensor(),\r\n","        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n","    ]),\r\n","}\r\n","\r\n","print(\"Initializing Datasets and Dataloaders...\")\r\n","\r\n","# Create training and validation datasets\r\n","image_datasets = {x: tv.datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\r\n","# Create training and validation dataloaders\r\n","dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']}\r\n","\r\n","# Detect if we have a GPU available\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Initializing Datasets and Dataloaders...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"hYNZTl3P44kA"},"source":["# **1. Обучите на нем модели ResNet 18 и VGG 16 с нуля (5-10 эпох)**"]},{"cell_type":"markdown","metadata":{"id":"q8ofIUtk4-F6"},"source":["## **ResNet 18**"]},{"cell_type":"code","metadata":{"id":"iH_9DeGd4ZVG","executionInfo":{"status":"ok","timestamp":1615926086529,"user_tz":-180,"elapsed":725,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["model = models.resnet18(pretrained=False)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISmWV3pkhQg8","executionInfo":{"status":"ok","timestamp":1615926087645,"user_tz":-180,"elapsed":480,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["model = model.to(dev)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"jxE-rmQfnNb4","executionInfo":{"status":"ok","timestamp":1615926089349,"user_tz":-180,"elapsed":703,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["## Убираем требование градиента:\r\n","for param in model.parameters():\r\n","    param.requires_grad = False"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xdmPY6ttnUwF","executionInfo":{"status":"ok","timestamp":1615926090789,"user_tz":-180,"elapsed":664,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"666cc266-a71e-4320-9c59-d68722208508"},"source":["model.fc"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=512, out_features=1000, bias=True)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"CT26xSv9na_0","executionInfo":{"status":"ok","timestamp":1615926094832,"user_tz":-180,"elapsed":632,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["model.fc = nn.Linear(in_features=512, out_features=2).to(dev)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BcB_4rElngxd","executionInfo":{"status":"ok","timestamp":1615926098115,"user_tz":-180,"elapsed":671,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"04f92b15-2ded-471f-be89-5d532e9bb88b"},"source":["print(\"Params to learn:\")\r\n","params_to_update = []\r\n","for name,param in model.named_parameters():\r\n","    if param.requires_grad == True:\r\n","        params_to_update.append(param)\r\n","        print(\"\\t\",name)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t fc.weight\n","\t fc.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZUeLFkWQoowW","executionInfo":{"status":"ok","timestamp":1615926101976,"user_tz":-180,"elapsed":637,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["def evaluate_accuracy(data_iter, net, dev):\n","    acc_sum, n = torch.Tensor([0]).to(dev), 0\n","    net.eval()\n","    for X, y in data_iter:\n","        X, y = X.to(dev), y.to(dev)\n","        acc_sum += (net(X).argmax(axis=1) == y).sum()\n","        n += y.shape[0]\n","    return acc_sum.item() / n"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"sb26I1fhscYv","executionInfo":{"status":"ok","timestamp":1615926104497,"user_tz":-180,"elapsed":631,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["def train(net, train_iter, test_iter, trainer, num_epochs, dev):\r\n","    loss = nn.CrossEntropyLoss(reduction='sum')\r\n","    net.train()\r\n","    for epoch in range(num_epochs):\r\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\r\n","        for X, y in train_iter:\r\n","            trainer.zero_grad()\r\n","            X, y = X.to(dev), y.to(dev)\r\n","            y_hat = net(X)\r\n","            l = loss(y_hat, y)\r\n","            l.backward()\r\n","            trainer.step()\r\n","            train_l_sum += l.item()\r\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\r\n","            n += y.shape[0]\r\n","            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\r\n","                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\r\n","        test_acc = evaluate_accuracy(test_iter, net, dev)\r\n","        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\r\n","              'time %.1f sec'\r\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\r\n","                 time.time() - start))"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMp9evAypj8o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615926349967,"user_tz":-180,"elapsed":243416,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"c0de815c-9f19-4511-b812-5b273afcb4a8"},"source":["lr, num_epochs = 0.001, 10\r\n","trainer = torch.optim.Adam(model.parameters(), lr=lr)\r\n","train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Step. time since epoch: 3.906. Train acc: 0.469. Train Loss: 27.953\n","Step. time since epoch: 5.839. Train acc: 0.594. Train Loss: 21.808\n","Step. time since epoch: 7.775. Train acc: 0.500. Train Loss: 22.784\n","Step. time since epoch: 9.712. Train acc: 0.469. Train Loss: 24.737\n","Step. time since epoch: 11.664. Train acc: 0.469. Train Loss: 24.108\n","Step. time since epoch: 13.634. Train acc: 0.438. Train Loss: 23.391\n","Step. time since epoch: 15.583. Train acc: 0.500. Train Loss: 22.956\n","Step. time since epoch: 16.838. Train acc: 0.250. Train Loss: 16.119\n","epoch 1, loss 0.7535, train acc 0.471, test acc 0.458, time 26.6 sec\n","Step. time since epoch: 3.566. Train acc: 0.688. Train Loss: 20.883\n","Step. time since epoch: 5.175. Train acc: 0.438. Train Loss: 23.722\n","Step. time since epoch: 6.792. Train acc: 0.531. Train Loss: 22.181\n","Step. time since epoch: 8.404. Train acc: 0.344. Train Loss: 24.504\n","Step. time since epoch: 10.010. Train acc: 0.469. Train Loss: 22.532\n","Step. time since epoch: 11.615. Train acc: 0.500. Train Loss: 22.718\n","Step. time since epoch: 13.210. Train acc: 0.594. Train Loss: 21.732\n","Step. time since epoch: 14.230. Train acc: 0.400. Train Loss: 14.870\n","epoch 2, loss 0.7096, train acc 0.500, test acc 0.490, time 24.0 sec\n","Step. time since epoch: 3.564. Train acc: 0.625. Train Loss: 21.927\n","Step. time since epoch: 5.175. Train acc: 0.500. Train Loss: 21.754\n","Step. time since epoch: 6.786. Train acc: 0.531. Train Loss: 22.057\n","Step. time since epoch: 8.383. Train acc: 0.281. Train Loss: 23.015\n","Step. time since epoch: 9.992. Train acc: 0.500. Train Loss: 22.161\n","Step. time since epoch: 11.581. Train acc: 0.469. Train Loss: 22.053\n","Step. time since epoch: 13.204. Train acc: 0.406. Train Loss: 22.561\n","Step. time since epoch: 14.235. Train acc: 0.550. Train Loss: 13.883\n","epoch 3, loss 0.6943, train acc 0.480, test acc 0.536, time 24.0 sec\n","Step. time since epoch: 3.653. Train acc: 0.531. Train Loss: 22.307\n","Step. time since epoch: 5.254. Train acc: 0.406. Train Loss: 22.554\n","Step. time since epoch: 6.876. Train acc: 0.625. Train Loss: 22.002\n","Step. time since epoch: 8.485. Train acc: 0.469. Train Loss: 22.414\n","Step. time since epoch: 10.094. Train acc: 0.406. Train Loss: 22.976\n","Step. time since epoch: 11.708. Train acc: 0.469. Train Loss: 22.177\n","Step. time since epoch: 13.305. Train acc: 0.531. Train Loss: 21.517\n","Step. time since epoch: 14.325. Train acc: 0.450. Train Loss: 14.141\n","epoch 4, loss 0.6971, train acc 0.488, test acc 0.601, time 24.0 sec\n","Step. time since epoch: 3.597. Train acc: 0.594. Train Loss: 21.571\n","Step. time since epoch: 5.211. Train acc: 0.375. Train Loss: 22.623\n","Step. time since epoch: 6.842. Train acc: 0.500. Train Loss: 22.041\n","Step. time since epoch: 8.450. Train acc: 0.406. Train Loss: 22.291\n","Step. time since epoch: 10.063. Train acc: 0.500. Train Loss: 22.298\n","Step. time since epoch: 11.660. Train acc: 0.531. Train Loss: 21.848\n","Step. time since epoch: 13.268. Train acc: 0.438. Train Loss: 22.159\n","Step. time since epoch: 14.291. Train acc: 0.500. Train Loss: 13.841\n","epoch 5, loss 0.6913, train acc 0.480, test acc 0.582, time 24.1 sec\n","Step. time since epoch: 3.512. Train acc: 0.562. Train Loss: 21.956\n","Step. time since epoch: 5.118. Train acc: 0.500. Train Loss: 22.260\n","Step. time since epoch: 6.753. Train acc: 0.469. Train Loss: 22.076\n","Step. time since epoch: 8.353. Train acc: 0.375. Train Loss: 22.462\n","Step. time since epoch: 9.962. Train acc: 0.656. Train Loss: 21.449\n","Step. time since epoch: 11.568. Train acc: 0.625. Train Loss: 21.967\n","Step. time since epoch: 13.184. Train acc: 0.469. Train Loss: 22.300\n","Step. time since epoch: 14.197. Train acc: 0.600. Train Loss: 13.957\n","epoch 6, loss 0.6903, train acc 0.529, test acc 0.588, time 24.0 sec\n","Step. time since epoch: 3.612. Train acc: 0.438. Train Loss: 22.292\n","Step. time since epoch: 5.231. Train acc: 0.594. Train Loss: 21.340\n","Step. time since epoch: 6.851. Train acc: 0.500. Train Loss: 22.016\n","Step. time since epoch: 8.459. Train acc: 0.625. Train Loss: 21.607\n","Step. time since epoch: 10.077. Train acc: 0.500. Train Loss: 21.948\n","Step. time since epoch: 11.678. Train acc: 0.469. Train Loss: 21.973\n","Step. time since epoch: 13.289. Train acc: 0.531. Train Loss: 22.151\n","Step. time since epoch: 14.311. Train acc: 0.450. Train Loss: 13.753\n","epoch 7, loss 0.6848, train acc 0.516, test acc 0.516, time 24.0 sec\n","Step. time since epoch: 3.583. Train acc: 0.438. Train Loss: 22.452\n","Step. time since epoch: 5.190. Train acc: 0.562. Train Loss: 21.969\n","Step. time since epoch: 6.788. Train acc: 0.469. Train Loss: 22.271\n","Step. time since epoch: 8.406. Train acc: 0.438. Train Loss: 22.322\n","Step. time since epoch: 10.024. Train acc: 0.531. Train Loss: 21.994\n","Step. time since epoch: 11.634. Train acc: 0.750. Train Loss: 20.883\n","Step. time since epoch: 13.235. Train acc: 0.562. Train Loss: 21.551\n","Step. time since epoch: 14.253. Train acc: 0.550. Train Loss: 13.583\n","epoch 8, loss 0.6845, train acc 0.537, test acc 0.569, time 24.0 sec\n","Step. time since epoch: 3.584. Train acc: 0.625. Train Loss: 21.939\n","Step. time since epoch: 5.188. Train acc: 0.594. Train Loss: 21.833\n","Step. time since epoch: 6.796. Train acc: 0.594. Train Loss: 21.677\n","Step. time since epoch: 8.397. Train acc: 0.625. Train Loss: 21.493\n","Step. time since epoch: 10.015. Train acc: 0.594. Train Loss: 21.625\n","Step. time since epoch: 11.614. Train acc: 0.500. Train Loss: 21.738\n","Step. time since epoch: 13.215. Train acc: 0.562. Train Loss: 21.802\n","Step. time since epoch: 14.239. Train acc: 0.600. Train Loss: 13.680\n","epoch 9, loss 0.6795, train acc 0.586, test acc 0.588, time 24.0 sec\n","Step. time since epoch: 3.557. Train acc: 0.531. Train Loss: 22.013\n","Step. time since epoch: 5.179. Train acc: 0.500. Train Loss: 21.868\n","Step. time since epoch: 6.791. Train acc: 0.531. Train Loss: 22.009\n","Step. time since epoch: 8.412. Train acc: 0.562. Train Loss: 21.533\n","Step. time since epoch: 10.023. Train acc: 0.719. Train Loss: 21.183\n","Step. time since epoch: 11.634. Train acc: 0.688. Train Loss: 21.336\n","Step. time since epoch: 13.264. Train acc: 0.625. Train Loss: 21.330\n","Step. time since epoch: 14.296. Train acc: 0.550. Train Loss: 13.735\n","epoch 10, loss 0.6763, train acc 0.590, test acc 0.582, time 24.0 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tEgtmsLH-jhy"},"source":["## **VGG16**"]},{"cell_type":"code","metadata":{"id":"hSBo1cWY-y9n","executionInfo":{"status":"ok","timestamp":1615924578379,"user_tz":-180,"elapsed":3040,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["model = models.vgg16(pretrained=False)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"-nj_5EZn-y-2","executionInfo":{"status":"ok","timestamp":1615924580875,"user_tz":-180,"elapsed":636,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["model = model.to(dev)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"dbhOfHr3mqSG","executionInfo":{"status":"ok","timestamp":1615924583362,"user_tz":-180,"elapsed":1356,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["## Убираем требование градиента:\r\n","for param in model.parameters():\r\n","    param.requires_grad = False"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4lU-uXLGmq_k","executionInfo":{"status":"ok","timestamp":1615924585025,"user_tz":-180,"elapsed":648,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"e9a8abe8-d873-4999-f1fa-a1da8c932b99"},"source":["model.classifier"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=25088, out_features=4096, bias=True)\n","  (1): ReLU(inplace=True)\n","  (2): Dropout(p=0.5, inplace=False)\n","  (3): Linear(in_features=4096, out_features=4096, bias=True)\n","  (4): ReLU(inplace=True)\n","  (5): Dropout(p=0.5, inplace=False)\n","  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"gqUjZ3-UmrBk","executionInfo":{"status":"ok","timestamp":1615924587543,"user_tz":-180,"elapsed":654,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["model.classifier[6] = nn.Linear(in_features=4096, out_features=2).to(dev)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-mJFTr2m15v","executionInfo":{"status":"ok","timestamp":1615924590819,"user_tz":-180,"elapsed":755,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"71645f3c-6610-467b-e984-f6a3cae52ae2"},"source":["print(\"Params to learn:\")\r\n","params_to_update = []\r\n","for name,param in model.named_parameters():\r\n","    if param.requires_grad == True:\r\n","        params_to_update.append(param)\r\n","        print(\"\\t\",name)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t classifier.6.weight\n","\t classifier.6.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k0dy_If3-zAK","executionInfo":{"status":"ok","timestamp":1615924595021,"user_tz":-180,"elapsed":608,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["def evaluate_accuracy(data_iter, net, dev):\r\n","    acc_sum, n = torch.Tensor([0]).to(dev), 0\r\n","    net.eval()\r\n","    for X, y in data_iter:\r\n","        X, y = X.to(dev), y.to(dev)\r\n","        acc_sum += (net(X).argmax(axis=1) == y).sum()\r\n","        n += y.shape[0]\r\n","    return acc_sum.item() / n"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFYPbUQ-_htj","executionInfo":{"status":"ok","timestamp":1615924597221,"user_tz":-180,"elapsed":652,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}}},"source":["def train(net, train_iter, test_iter, trainer, num_epochs, dev):\r\n","    loss = nn.CrossEntropyLoss(reduction='sum')\r\n","    net.train()\r\n","    for epoch in range(num_epochs):\r\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\r\n","        for X, y in train_iter:\r\n","            trainer.zero_grad()\r\n","            X, y = X.to(dev), y.to(dev)\r\n","            y_hat = net(X)\r\n","            l = loss(y_hat, y)\r\n","            l.backward()\r\n","            trainer.step()\r\n","            train_l_sum += l.item()\r\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\r\n","            n += y.shape[0]\r\n","            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\r\n","                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\r\n","        test_acc = evaluate_accuracy(test_iter, net, dev)\r\n","        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\r\n","              'time %.1f sec'\r\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\r\n","                 time.time() - start))"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gqol1Ii9_hu4","executionInfo":{"status":"ok","timestamp":1615926025299,"user_tz":-180,"elapsed":1424416,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"e3caddbc-e4b1-4705-c98c-176c31354c72"},"source":["lr, num_epochs = 0.001, 10\r\n","trainer = torch.optim.Adam(model.parameters(), lr=lr)\r\n","train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Step. time since epoch: 13.711. Train acc: 0.688. Train Loss: 21.577\n","Step. time since epoch: 24.742. Train acc: 0.406. Train Loss: 22.594\n","Step. time since epoch: 35.770. Train acc: 0.500. Train Loss: 22.796\n","Step. time since epoch: 46.750. Train acc: 0.406. Train Loss: 22.999\n","Step. time since epoch: 57.726. Train acc: 0.438. Train Loss: 22.146\n","Step. time since epoch: 68.676. Train acc: 0.562. Train Loss: 21.963\n","Step. time since epoch: 79.714. Train acc: 0.500. Train Loss: 22.563\n","Step. time since epoch: 86.800. Train acc: 0.400. Train Loss: 14.322\n","epoch 1, loss 0.7007, train acc 0.492, test acc 0.542, time 142.6 sec\n","Step. time since epoch: 14.073. Train acc: 0.594. Train Loss: 21.855\n","Step. time since epoch: 25.023. Train acc: 0.438. Train Loss: 22.217\n","Step. time since epoch: 35.976. Train acc: 0.438. Train Loss: 22.199\n","Step. time since epoch: 46.929. Train acc: 0.531. Train Loss: 22.137\n","Step. time since epoch: 57.900. Train acc: 0.656. Train Loss: 21.680\n","Step. time since epoch: 68.818. Train acc: 0.500. Train Loss: 22.505\n","Step. time since epoch: 79.731. Train acc: 0.438. Train Loss: 23.035\n","Step. time since epoch: 86.701. Train acc: 0.350. Train Loss: 14.770\n","epoch 2, loss 0.6984, train acc 0.500, test acc 0.458, time 142.5 sec\n","Step. time since epoch: 14.066. Train acc: 0.594. Train Loss: 21.657\n","Step. time since epoch: 25.011. Train acc: 0.594. Train Loss: 21.705\n","Step. time since epoch: 35.966. Train acc: 0.406. Train Loss: 22.629\n","Step. time since epoch: 46.914. Train acc: 0.625. Train Loss: 21.809\n","Step. time since epoch: 57.859. Train acc: 0.625. Train Loss: 22.060\n","Step. time since epoch: 68.784. Train acc: 0.656. Train Loss: 21.960\n","Step. time since epoch: 79.704. Train acc: 0.531. Train Loss: 22.006\n","Step. time since epoch: 86.659. Train acc: 0.750. Train Loss: 13.249\n","epoch 3, loss 0.6847, train acc 0.590, test acc 0.542, time 142.3 sec\n","Step. time since epoch: 14.033. Train acc: 0.375. Train Loss: 22.835\n","Step. time since epoch: 24.953. Train acc: 0.531. Train Loss: 21.952\n","Step. time since epoch: 35.896. Train acc: 0.469. Train Loss: 22.277\n","Step. time since epoch: 46.848. Train acc: 0.500. Train Loss: 21.782\n","Step. time since epoch: 57.809. Train acc: 0.594. Train Loss: 21.190\n","Step. time since epoch: 68.717. Train acc: 0.562. Train Loss: 21.410\n","Step. time since epoch: 79.634. Train acc: 0.469. Train Loss: 22.107\n","Step. time since epoch: 86.598. Train acc: 0.450. Train Loss: 14.042\n","epoch 4, loss 0.6869, train acc 0.496, test acc 0.556, time 142.2 sec\n","Step. time since epoch: 14.010. Train acc: 0.438. Train Loss: 22.427\n","Step. time since epoch: 24.944. Train acc: 0.500. Train Loss: 21.772\n","Step. time since epoch: 35.819. Train acc: 0.750. Train Loss: 21.669\n","Step. time since epoch: 46.764. Train acc: 0.594. Train Loss: 21.780\n","Step. time since epoch: 57.748. Train acc: 0.375. Train Loss: 21.987\n","Step. time since epoch: 68.694. Train acc: 0.656. Train Loss: 21.714\n","Step. time since epoch: 79.620. Train acc: 0.656. Train Loss: 21.916\n","Step. time since epoch: 86.596. Train acc: 0.500. Train Loss: 13.904\n","epoch 5, loss 0.6851, train acc 0.561, test acc 0.588, time 142.3 sec\n","Step. time since epoch: 14.097. Train acc: 0.562. Train Loss: 21.982\n","Step. time since epoch: 25.013. Train acc: 0.750. Train Loss: 21.570\n","Step. time since epoch: 35.957. Train acc: 0.781. Train Loss: 21.576\n","Step. time since epoch: 46.846. Train acc: 0.781. Train Loss: 21.343\n","Step. time since epoch: 57.750. Train acc: 0.562. Train Loss: 21.477\n","Step. time since epoch: 68.684. Train acc: 0.469. Train Loss: 22.278\n","Step. time since epoch: 79.588. Train acc: 0.500. Train Loss: 21.892\n","Step. time since epoch: 86.582. Train acc: 0.500. Train Loss: 13.779\n","epoch 6, loss 0.6799, train acc 0.619, test acc 0.582, time 142.1 sec\n","Step. time since epoch: 14.126. Train acc: 0.719. Train Loss: 20.811\n","Step. time since epoch: 25.077. Train acc: 0.500. Train Loss: 21.859\n","Step. time since epoch: 36.050. Train acc: 0.562. Train Loss: 21.447\n","Step. time since epoch: 47.001. Train acc: 0.438. Train Loss: 22.500\n","Step. time since epoch: 57.951. Train acc: 0.594. Train Loss: 21.577\n","Step. time since epoch: 68.905. Train acc: 0.719. Train Loss: 21.247\n","Step. time since epoch: 79.867. Train acc: 0.469. Train Loss: 21.829\n","Step. time since epoch: 86.881. Train acc: 0.600. Train Loss: 13.778\n","epoch 7, loss 0.6764, train acc 0.574, test acc 0.490, time 142.6 sec\n","Step. time since epoch: 14.017. Train acc: 0.688. Train Loss: 20.981\n","Step. time since epoch: 24.939. Train acc: 0.562. Train Loss: 21.353\n","Step. time since epoch: 35.899. Train acc: 0.594. Train Loss: 21.954\n","Step. time since epoch: 46.852. Train acc: 0.438. Train Loss: 22.752\n","Step. time since epoch: 57.806. Train acc: 0.750. Train Loss: 21.025\n","Step. time since epoch: 68.751. Train acc: 0.469. Train Loss: 21.915\n","Step. time since epoch: 79.693. Train acc: 0.375. Train Loss: 22.796\n","Step. time since epoch: 86.671. Train acc: 0.400. Train Loss: 14.197\n","epoch 8, loss 0.6843, train acc 0.541, test acc 0.549, time 142.3 sec\n","Step. time since epoch: 14.052. Train acc: 0.500. Train Loss: 22.301\n","Step. time since epoch: 25.017. Train acc: 0.469. Train Loss: 21.877\n","Step. time since epoch: 35.939. Train acc: 0.625. Train Loss: 21.261\n","Step. time since epoch: 46.856. Train acc: 0.719. Train Loss: 21.055\n","Step. time since epoch: 57.844. Train acc: 0.625. Train Loss: 21.364\n","Step. time since epoch: 68.773. Train acc: 0.656. Train Loss: 21.286\n","Step. time since epoch: 79.731. Train acc: 0.500. Train Loss: 21.929\n","Step. time since epoch: 86.747. Train acc: 0.750. Train Loss: 12.917\n","epoch 9, loss 0.6721, train acc 0.598, test acc 0.529, time 142.4 sec\n","Step. time since epoch: 14.050. Train acc: 0.656. Train Loss: 21.325\n","Step. time since epoch: 24.926. Train acc: 0.656. Train Loss: 21.309\n","Step. time since epoch: 35.861. Train acc: 0.719. Train Loss: 21.262\n","Step. time since epoch: 46.784. Train acc: 0.625. Train Loss: 21.409\n","Step. time since epoch: 57.756. Train acc: 0.781. Train Loss: 20.509\n","Step. time since epoch: 68.739. Train acc: 0.531. Train Loss: 21.616\n","Step. time since epoch: 79.702. Train acc: 0.656. Train Loss: 20.925\n","Step. time since epoch: 86.699. Train acc: 0.700. Train Loss: 12.904\n","epoch 10, loss 0.6609, train acc 0.664, test acc 0.601, time 142.3 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xd6TxUYUEhxD"},"source":["# release CUDA\r\n","#model.eval()\r\n","#torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f2bg1El5FibY"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"id2lgwqqFidK"},"source":["# **2. Обучите на нем модели ResNet 18 и VGG 16 с использованием FineTuning (5-10 эпох)**"]},{"cell_type":"markdown","metadata":{"id":"9sE_4qUwFkcK"},"source":["## **ResNet 18 FineTuning (pretrained)** "]},{"cell_type":"code","metadata":{"id":"28uOypTPR3EJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["16f6bec3dbc546e59e5922b3aec89088","33f4346dc1ba46d49f1bf3898bfc179c","ce2c5deed04a445d8335ff4ddb2372b0","afa4ef656ee243fea0b379004e36989e","3556afe8fe1241a299931ee584c9592f","d62cee62a7fc4c0fb46724bbacec4b06","8ac88d5a635746d387429c4ff6e65b69","8c8dd0f1db1a4c309420acebbf598657"]},"id":"OsZsgD4MF1L9","executionInfo":{"status":"ok","timestamp":1613940021567,"user_tz":-180,"elapsed":2448,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"cefb8650-7bfc-46e4-be2e-664b6626417a"},"source":["model = models.resnet18(pretrained=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16f6bec3dbc546e59e5922b3aec89088","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8SWegaHsGxEg"},"source":["model = model.to(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PJJ3vRH5GxF8"},"source":["## Убираем требование градиента:\r\n","for param in model.parameters():\r\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhTa2cEAG9pe","executionInfo":{"status":"ok","timestamp":1613940055039,"user_tz":-180,"elapsed":516,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"d2945dff-f40d-4818-c982-dcd1b5740d2e"},"source":["model.fc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=512, out_features=1000, bias=True)"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"sthcvT_0G9qy"},"source":["model.fc = nn.Linear(in_features=512, out_features=2).to(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmpFsn80Hjso","executionInfo":{"status":"ok","timestamp":1613940060296,"user_tz":-180,"elapsed":522,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"6fc35a5b-6ca5-4cb7-cffe-abdff879f487"},"source":["print(\"Params to learn:\")\r\n","params_to_update = []\r\n","for name,param in model.named_parameters():\r\n","    if param.requires_grad == True:\r\n","        params_to_update.append(param)\r\n","        print(\"\\t\",name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t fc.weight\n","\t fc.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yHeNk8DLHjt8"},"source":["def evaluate_accuracy(data_iter, net, dev):\r\n","    acc_sum, n = torch.Tensor([0]).to(dev), 0\r\n","    net.eval()\r\n","    for X, y in data_iter:\r\n","        X, y = X.to(dev), y.to(dev)\r\n","        acc_sum += (net(X).argmax(axis=1) == y).sum()\r\n","        n += y.shape[0]\r\n","    return acc_sum.item() / n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zgadODPGIVe0"},"source":["def train(net, train_iter, test_iter, trainer, num_epochs, dev):\r\n","    loss = nn.CrossEntropyLoss(reduction='sum')\r\n","    net.train()\r\n","    for epoch in range(num_epochs):\r\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\r\n","        for X, y in train_iter:\r\n","            trainer.zero_grad()\r\n","            X, y = X.to(dev), y.to(dev)\r\n","            y_hat = net(X)\r\n","            l = loss(y_hat, y)\r\n","            l.backward()\r\n","            trainer.step()\r\n","            train_l_sum += l.item()\r\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\r\n","            n += y.shape[0]\r\n","            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\r\n","                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\r\n","        test_acc = evaluate_accuracy(test_iter, net, dev)\r\n","        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\r\n","              'time %.1f sec'\r\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\r\n","                 time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JS5iQxMLIeM8","executionInfo":{"status":"ok","timestamp":1613940419557,"user_tz":-180,"elapsed":348498,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"1c512de4-1e8a-42ce-d45b-0f2a714a3b69"},"source":["lr, num_epochs = 0.001, 10\r\n","trainer = torch.optim.Adam(model.parameters(), lr=lr)\r\n","train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Step. time since epoch: 4.939. Train acc: 0.531. Train Loss: 25.279\n","Step. time since epoch: 7.649. Train acc: 0.406. Train Loss: 28.519\n","Step. time since epoch: 10.330. Train acc: 0.469. Train Loss: 24.553\n","Step. time since epoch: 13.009. Train acc: 0.406. Train Loss: 28.903\n","Step. time since epoch: 15.731. Train acc: 0.438. Train Loss: 26.804\n","Step. time since epoch: 18.404. Train acc: 0.688. Train Loss: 18.240\n","Step. time since epoch: 21.097. Train acc: 0.625. Train Loss: 19.237\n","Step. time since epoch: 22.832. Train acc: 0.750. Train Loss: 11.736\n","epoch 1, loss 0.7511, train acc 0.529, test acc 0.673, time 36.8 sec\n","Step. time since epoch: 4.455. Train acc: 0.812. Train Loss: 16.578\n","Step. time since epoch: 6.884. Train acc: 0.688. Train Loss: 17.979\n","Step. time since epoch: 9.314. Train acc: 0.781. Train Loss: 15.902\n","Step. time since epoch: 11.719. Train acc: 0.719. Train Loss: 19.145\n","Step. time since epoch: 14.124. Train acc: 0.781. Train Loss: 15.939\n","Step. time since epoch: 16.555. Train acc: 0.875. Train Loss: 12.830\n","Step. time since epoch: 18.990. Train acc: 0.875. Train Loss: 13.419\n","Step. time since epoch: 20.552. Train acc: 0.850. Train Loss: 9.132\n","epoch 2, loss 0.4956, train acc 0.795, test acc 0.869, time 34.5 sec\n","Step. time since epoch: 4.410. Train acc: 0.781. Train Loss: 15.788\n","Step. time since epoch: 6.823. Train acc: 0.812. Train Loss: 13.797\n","Step. time since epoch: 9.237. Train acc: 0.969. Train Loss: 10.411\n","Step. time since epoch: 11.648. Train acc: 0.969. Train Loss: 9.925\n","Step. time since epoch: 14.056. Train acc: 0.969. Train Loss: 9.878\n","Step. time since epoch: 16.484. Train acc: 0.969. Train Loss: 8.976\n","Step. time since epoch: 18.886. Train acc: 0.938. Train Loss: 9.287\n","Step. time since epoch: 20.494. Train acc: 0.950. Train Loss: 5.245\n","epoch 3, loss 0.3414, train acc 0.918, test acc 0.915, time 34.5 sec\n","Step. time since epoch: 4.472. Train acc: 0.938. Train Loss: 9.157\n","Step. time since epoch: 6.894. Train acc: 0.969. Train Loss: 9.528\n","Step. time since epoch: 9.317. Train acc: 1.000. Train Loss: 7.392\n","Step. time since epoch: 11.774. Train acc: 0.938. Train Loss: 9.661\n","Step. time since epoch: 14.166. Train acc: 0.969. Train Loss: 7.178\n","Step. time since epoch: 16.595. Train acc: 1.000. Train Loss: 4.934\n","Step. time since epoch: 19.010. Train acc: 0.875. Train Loss: 9.769\n","Step. time since epoch: 20.590. Train acc: 1.000. Train Loss: 3.629\n","epoch 4, loss 0.2510, train acc 0.959, test acc 0.935, time 34.7 sec\n","Step. time since epoch: 4.478. Train acc: 1.000. Train Loss: 5.684\n","Step. time since epoch: 6.889. Train acc: 0.969. Train Loss: 7.361\n","Step. time since epoch: 9.286. Train acc: 0.969. Train Loss: 5.280\n","Step. time since epoch: 11.687. Train acc: 0.969. Train Loss: 7.777\n","Step. time since epoch: 14.091. Train acc: 0.938. Train Loss: 6.148\n","Step. time since epoch: 16.535. Train acc: 1.000. Train Loss: 4.614\n","Step. time since epoch: 18.943. Train acc: 0.938. Train Loss: 5.591\n","Step. time since epoch: 20.517. Train acc: 0.950. Train Loss: 5.743\n","epoch 5, loss 0.1975, train acc 0.967, test acc 0.941, time 34.6 sec\n","Step. time since epoch: 4.559. Train acc: 1.000. Train Loss: 4.130\n","Step. time since epoch: 7.032. Train acc: 1.000. Train Loss: 6.846\n","Step. time since epoch: 9.441. Train acc: 0.969. Train Loss: 5.955\n","Step. time since epoch: 11.858. Train acc: 1.000. Train Loss: 6.180\n","Step. time since epoch: 14.274. Train acc: 0.938. Train Loss: 6.774\n","Step. time since epoch: 16.687. Train acc: 1.000. Train Loss: 2.987\n","Step. time since epoch: 19.093. Train acc: 0.969. Train Loss: 6.007\n","Step. time since epoch: 20.667. Train acc: 0.950. Train Loss: 2.942\n","epoch 6, loss 0.1714, train acc 0.980, test acc 0.948, time 34.6 sec\n","Step. time since epoch: 4.476. Train acc: 1.000. Train Loss: 5.968\n","Step. time since epoch: 6.889. Train acc: 1.000. Train Loss: 3.337\n","Step. time since epoch: 9.306. Train acc: 0.969. Train Loss: 4.062\n","Step. time since epoch: 11.739. Train acc: 0.969. Train Loss: 4.644\n","Step. time since epoch: 14.145. Train acc: 0.969. Train Loss: 5.228\n","Step. time since epoch: 16.553. Train acc: 1.000. Train Loss: 4.273\n","Step. time since epoch: 18.962. Train acc: 0.938. Train Loss: 6.352\n","Step. time since epoch: 20.515. Train acc: 0.950. Train Loss: 2.389\n","epoch 7, loss 0.1486, train acc 0.975, test acc 0.954, time 34.5 sec\n","Step. time since epoch: 4.455. Train acc: 1.000. Train Loss: 2.557\n","Step. time since epoch: 6.868. Train acc: 0.969. Train Loss: 3.277\n","Step. time since epoch: 9.264. Train acc: 0.969. Train Loss: 5.763\n","Step. time since epoch: 11.675. Train acc: 0.969. Train Loss: 4.530\n","Step. time since epoch: 14.110. Train acc: 0.969. Train Loss: 4.521\n","Step. time since epoch: 16.504. Train acc: 1.000. Train Loss: 5.331\n","Step. time since epoch: 18.909. Train acc: 1.000. Train Loss: 4.188\n","Step. time since epoch: 20.467. Train acc: 0.950. Train Loss: 2.775\n","epoch 8, loss 0.1350, train acc 0.980, test acc 0.954, time 34.4 sec\n","Step. time since epoch: 4.439. Train acc: 1.000. Train Loss: 3.188\n","Step. time since epoch: 6.863. Train acc: 0.969. Train Loss: 4.811\n","Step. time since epoch: 9.273. Train acc: 0.969. Train Loss: 4.873\n","Step. time since epoch: 11.670. Train acc: 0.969. Train Loss: 3.541\n","Step. time since epoch: 14.095. Train acc: 1.000. Train Loss: 3.165\n","Step. time since epoch: 16.497. Train acc: 1.000. Train Loss: 3.212\n","Step. time since epoch: 18.910. Train acc: 0.969. Train Loss: 5.409\n","Step. time since epoch: 20.471. Train acc: 1.000. Train Loss: 1.727\n","epoch 9, loss 0.1226, train acc 0.984, test acc 0.954, time 34.6 sec\n","Step. time since epoch: 4.491. Train acc: 0.969. Train Loss: 4.884\n","Step. time since epoch: 6.899. Train acc: 1.000. Train Loss: 2.647\n","Step. time since epoch: 9.334. Train acc: 1.000. Train Loss: 2.392\n","Step. time since epoch: 11.751. Train acc: 0.969. Train Loss: 5.073\n","Step. time since epoch: 14.167. Train acc: 1.000. Train Loss: 2.625\n","Step. time since epoch: 16.557. Train acc: 1.000. Train Loss: 4.361\n","Step. time since epoch: 18.962. Train acc: 0.969. Train Loss: 3.709\n","Step. time since epoch: 20.553. Train acc: 1.000. Train Loss: 2.212\n","epoch 10, loss 0.1144, train acc 0.988, test acc 0.948, time 34.5 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2DtLfFDJIrxM"},"source":["\r\n"," ## **VGG 16 FineTuning (pretrained)**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y5HrjrbzWaW7","executionInfo":{"status":"ok","timestamp":1613940505864,"user_tz":-180,"elapsed":523,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"6e637eec-31d0-4412-fa11-c08416c23d65"},"source":["dev"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["9bef0475445b4fadbbd9298ce161e953","5f6535abb7c74669b9f1dbf3359c98cb","071f105b4b514f058ee74322fbed281a","350e2bb3726a4cbabe2ce1a271e19ced","baf6094168a54293be649e1ae8024492","f10f21051eb042d09490a339e36a31a4","bfa4054e3ef14961b3ed6dc1ac3ad233","b7e5715cfc2a4df4858a1db20104282f"]},"id":"vhY64g9kI4XH","executionInfo":{"status":"ok","timestamp":1613940529082,"user_tz":-180,"elapsed":16439,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"d4403659-436a-4c22-e15f-1072b461a29f"},"source":["model = models.vgg16(pretrained=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9bef0475445b4fadbbd9298ce161e953","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Fw7k-6JJV4W"},"source":["model = model.to(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"znQvVhMEJbfd"},"source":["## Убираем требование градиента:\r\n","for param in model.parameters():\r\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6on01GwmJgqb","executionInfo":{"status":"ok","timestamp":1615924442362,"user_tz":-180,"elapsed":585,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"bcb4c85b-8eed-46eb-bd1c-90b11f12dc1d"},"source":["model.classifier"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=25088, out_features=4096, bias=True)\n","  (1): ReLU(inplace=True)\n","  (2): Dropout(p=0.5, inplace=False)\n","  (3): Linear(in_features=4096, out_features=4096, bias=True)\n","  (4): ReLU(inplace=True)\n","  (5): Dropout(p=0.5, inplace=False)\n","  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"AijF7x4FJnr2"},"source":["model.classifier[6] = nn.Linear(in_features=4096, out_features=2).to(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnnLFtX1JsK2","executionInfo":{"status":"ok","timestamp":1613940558217,"user_tz":-180,"elapsed":513,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"17781a80-faf0-4715-cc31-65255fd5fe07"},"source":["print(\"Params to learn:\")\r\n","params_to_update = []\r\n","for name,param in model.named_parameters():\r\n","    if param.requires_grad == True:\r\n","        params_to_update.append(param)\r\n","        print(\"\\t\",name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t classifier.6.weight\n","\t classifier.6.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9RQP8j-2JsMO"},"source":["def evaluate_accuracy(data_iter, net, dev):\r\n","    acc_sum, n = torch.Tensor([0]).to(dev), 0\r\n","    net.eval()\r\n","    for X, y in data_iter:\r\n","        X, y = X.to(dev), y.to(dev)\r\n","        acc_sum += (net(X).argmax(axis=1) == y).sum()\r\n","        n += y.shape[0]\r\n","    return acc_sum.item() / n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2MSkvtD9J5yl"},"source":["def train(net, train_iter, test_iter, trainer, num_epochs, dev):\r\n","    loss = nn.CrossEntropyLoss(reduction='sum')\r\n","    net.train()\r\n","    for epoch in range(num_epochs):\r\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\r\n","        for X, y in train_iter:\r\n","            trainer.zero_grad()\r\n","            X, y = X.to(dev), y.to(dev)\r\n","            y_hat = net(X)\r\n","            l = loss(y_hat, y)\r\n","            l.backward()\r\n","            trainer.step()\r\n","            train_l_sum += l.item()\r\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\r\n","            n += y.shape[0]\r\n","            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\r\n","                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\r\n","        test_acc = evaluate_accuracy(test_iter, net, dev)\r\n","        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\r\n","              'time %.1f sec'\r\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\r\n","                 time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fF3q56ZhKA4w","executionInfo":{"status":"ok","timestamp":1613942723936,"user_tz":-180,"elapsed":2156491,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"6f55404d-0130-4bc6-dc03-e400ec09a3bf"},"source":["lr, num_epochs = 0.001, 10\r\n","trainer = torch.optim.Adam(model.parameters(), lr=lr)\r\n","train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Step. time since epoch: 20.663. Train acc: 0.406. Train Loss: 28.631\n","Step. time since epoch: 37.458. Train acc: 0.750. Train Loss: 14.702\n","Step. time since epoch: 54.332. Train acc: 0.812. Train Loss: 13.320\n","Step. time since epoch: 71.246. Train acc: 0.875. Train Loss: 9.190\n","Step. time since epoch: 88.099. Train acc: 0.938. Train Loss: 8.278\n","Step. time since epoch: 104.910. Train acc: 0.938. Train Loss: 7.254\n","Step. time since epoch: 121.792. Train acc: 0.906. Train Loss: 6.216\n","Step. time since epoch: 132.521. Train acc: 0.900. Train Loss: 3.281\n","epoch 1, loss 0.3724, train acc 0.811, test acc 0.961, time 216.5 sec\n","Step. time since epoch: 19.930. Train acc: 0.969. Train Loss: 3.729\n","Step. time since epoch: 36.818. Train acc: 0.938. Train Loss: 4.116\n","Step. time since epoch: 53.798. Train acc: 0.969. Train Loss: 2.965\n","Step. time since epoch: 70.633. Train acc: 0.938. Train Loss: 4.625\n","Step. time since epoch: 87.642. Train acc: 0.938. Train Loss: 4.408\n","Step. time since epoch: 104.617. Train acc: 0.938. Train Loss: 3.419\n","Step. time since epoch: 121.484. Train acc: 1.000. Train Loss: 2.709\n","Step. time since epoch: 132.126. Train acc: 1.000. Train Loss: 1.134\n","epoch 2, loss 0.1111, train acc 0.959, test acc 0.961, time 215.9 sec\n","Step. time since epoch: 19.856. Train acc: 0.969. Train Loss: 2.529\n","Step. time since epoch: 36.720. Train acc: 0.969. Train Loss: 2.101\n","Step. time since epoch: 53.615. Train acc: 1.000. Train Loss: 2.212\n","Step. time since epoch: 70.469. Train acc: 1.000. Train Loss: 2.239\n","Step. time since epoch: 87.536. Train acc: 1.000. Train Loss: 0.925\n","Step. time since epoch: 104.432. Train acc: 1.000. Train Loss: 0.810\n","Step. time since epoch: 121.305. Train acc: 0.938. Train Loss: 3.589\n","Step. time since epoch: 132.036. Train acc: 1.000. Train Loss: 1.359\n","epoch 3, loss 0.0646, train acc 0.984, test acc 0.961, time 215.9 sec\n","Step. time since epoch: 19.884. Train acc: 1.000. Train Loss: 1.026\n","Step. time since epoch: 36.799. Train acc: 1.000. Train Loss: 0.529\n","Step. time since epoch: 53.714. Train acc: 0.938. Train Loss: 3.074\n","Step. time since epoch: 70.621. Train acc: 0.969. Train Loss: 1.999\n","Step. time since epoch: 87.525. Train acc: 0.969. Train Loss: 1.877\n","Step. time since epoch: 104.319. Train acc: 1.000. Train Loss: 0.927\n","Step. time since epoch: 121.233. Train acc: 1.000. Train Loss: 1.936\n","Step. time since epoch: 131.925. Train acc: 1.000. Train Loss: 0.233\n","epoch 4, loss 0.0475, train acc 0.984, test acc 0.967, time 215.6 sec\n","Step. time since epoch: 19.988. Train acc: 1.000. Train Loss: 0.810\n","Step. time since epoch: 36.912. Train acc: 1.000. Train Loss: 1.238\n","Step. time since epoch: 53.771. Train acc: 1.000. Train Loss: 0.300\n","Step. time since epoch: 70.715. Train acc: 1.000. Train Loss: 0.709\n","Step. time since epoch: 87.708. Train acc: 0.969. Train Loss: 1.964\n","Step. time since epoch: 104.506. Train acc: 1.000. Train Loss: 0.478\n","Step. time since epoch: 121.396. Train acc: 1.000. Train Loss: 1.879\n","Step. time since epoch: 132.052. Train acc: 1.000. Train Loss: 0.463\n","epoch 5, loss 0.0321, train acc 0.996, test acc 0.967, time 215.9 sec\n","Step. time since epoch: 19.810. Train acc: 1.000. Train Loss: 0.698\n","Step. time since epoch: 36.670. Train acc: 1.000. Train Loss: 0.342\n","Step. time since epoch: 53.506. Train acc: 1.000. Train Loss: 0.735\n","Step. time since epoch: 70.353. Train acc: 1.000. Train Loss: 0.506\n","Step. time since epoch: 87.184. Train acc: 1.000. Train Loss: 1.254\n","Step. time since epoch: 104.074. Train acc: 1.000. Train Loss: 1.188\n","Step. time since epoch: 120.932. Train acc: 1.000. Train Loss: 0.560\n","Step. time since epoch: 131.546. Train acc: 1.000. Train Loss: 0.657\n","epoch 6, loss 0.0243, train acc 1.000, test acc 0.967, time 215.3 sec\n","Step. time since epoch: 19.794. Train acc: 1.000. Train Loss: 0.666\n","Step. time since epoch: 36.609. Train acc: 1.000. Train Loss: 1.056\n","Step. time since epoch: 53.409. Train acc: 1.000. Train Loss: 0.532\n","Step. time since epoch: 70.220. Train acc: 1.000. Train Loss: 0.701\n","Step. time since epoch: 87.091. Train acc: 1.000. Train Loss: 0.536\n","Step. time since epoch: 103.929. Train acc: 1.000. Train Loss: 0.530\n","Step. time since epoch: 120.753. Train acc: 1.000. Train Loss: 0.581\n","Step. time since epoch: 131.429. Train acc: 1.000. Train Loss: 0.260\n","epoch 7, loss 0.0199, train acc 1.000, test acc 0.974, time 215.0 sec\n","Step. time since epoch: 19.868. Train acc: 1.000. Train Loss: 0.622\n","Step. time since epoch: 36.657. Train acc: 1.000. Train Loss: 0.544\n","Step. time since epoch: 53.572. Train acc: 1.000. Train Loss: 0.470\n","Step. time since epoch: 70.366. Train acc: 1.000. Train Loss: 0.511\n","Step. time since epoch: 87.153. Train acc: 1.000. Train Loss: 0.837\n","Step. time since epoch: 104.179. Train acc: 1.000. Train Loss: 0.432\n","Step. time since epoch: 120.989. Train acc: 1.000. Train Loss: 0.532\n","Step. time since epoch: 131.623. Train acc: 1.000. Train Loss: 0.088\n","epoch 8, loss 0.0165, train acc 1.000, test acc 0.974, time 215.0 sec\n","Step. time since epoch: 19.851. Train acc: 1.000. Train Loss: 0.280\n","Step. time since epoch: 36.688. Train acc: 1.000. Train Loss: 0.560\n","Step. time since epoch: 53.512. Train acc: 1.000. Train Loss: 0.788\n","Step. time since epoch: 70.438. Train acc: 1.000. Train Loss: 0.197\n","Step. time since epoch: 87.226. Train acc: 1.000. Train Loss: 0.391\n","Step. time since epoch: 104.085. Train acc: 1.000. Train Loss: 0.619\n","Step. time since epoch: 120.899. Train acc: 1.000. Train Loss: 0.410\n","Step. time since epoch: 131.584. Train acc: 1.000. Train Loss: 0.222\n","epoch 9, loss 0.0142, train acc 1.000, test acc 0.974, time 215.4 sec\n","Step. time since epoch: 19.825. Train acc: 1.000. Train Loss: 0.424\n","Step. time since epoch: 36.701. Train acc: 1.000. Train Loss: 0.572\n","Step. time since epoch: 53.553. Train acc: 1.000. Train Loss: 0.420\n","Step. time since epoch: 70.346. Train acc: 1.000. Train Loss: 0.361\n","Step. time since epoch: 87.140. Train acc: 1.000. Train Loss: 0.226\n","Step. time since epoch: 103.992. Train acc: 1.000. Train Loss: 0.398\n","Step. time since epoch: 120.789. Train acc: 1.000. Train Loss: 0.360\n","Step. time since epoch: 131.419. Train acc: 1.000. Train Loss: 0.291\n","epoch 10, loss 0.0125, train acc 1.000, test acc 0.974, time 214.9 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IY1zF6jUKF5r"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mk8o6NTFMmGf"},"source":["# **3. Добавьте аугментацию данных к пункту 2**"]},{"cell_type":"markdown","metadata":{"id":"JCK28SWCOND1"},"source":["Проведём аугментацию на тренировочных данных и обучим модели ResNet 18 и VGG 16"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KiwD9ucNL5dE","executionInfo":{"status":"ok","timestamp":1613942856918,"user_tz":-180,"elapsed":532,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"51b543a8-4139-44ab-95f5-dbabda441b9f"},"source":["# Data augmentation and normalization for training\r\n","# Just normalization for validation\r\n","data_transforms = {\r\n","    'train': tv.transforms.Compose([\r\n","        tv.transforms.RandomResizedCrop(224),\r\n","        tv.transforms.RandomHorizontalFlip(),\r\n","        tv.transforms.RandomVerticalFlip(),\r\n","        tv.transforms.ToTensor(),\r\n","        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n","    ]),\r\n","    'val': tv.transforms.Compose([\r\n","        tv.transforms.Resize(256),\r\n","        tv.transforms.CenterCrop(224),\r\n","        tv.transforms.ToTensor(),\r\n","        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n","    ]),\r\n","}\r\n","\r\n","print(\"Initializing Datasets and Dataloaders...\")\r\n","\r\n","# Create training and validation datasets\r\n","image_datasets = {x: tv.datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\r\n","# Create training and validation dataloaders\r\n","dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']}\r\n","\r\n","# Detect if we have a GPU available\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Initializing Datasets and Dataloaders...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"un1Jv5TxNxlg"},"source":["## **ResNet 18 FineTuning (pretrained) + augmentation** "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpNfd2hPNbM8","executionInfo":{"status":"ok","timestamp":1613942909699,"user_tz":-180,"elapsed":507,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"0e7592c7-0d06-4f3f-ac5f-f3617f0f4bf5"},"source":["device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"9Fiirjm-NbOY"},"source":["model = models.resnet18(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tI7UmmyqOkG_"},"source":["model = model.to(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuBeRQTdOlnp","executionInfo":{"status":"ok","timestamp":1613942922244,"user_tz":-180,"elapsed":527,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"4ca69d51-a9ab-4003-80f9-5a59c1dd4a41"},"source":["model.fc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=512, out_features=1000, bias=True)"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"LXUy0kTiOlpE"},"source":["model.fc = nn.Linear(in_features=512, out_features=2).to(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jL6coOYGOwNh","executionInfo":{"status":"ok","timestamp":1613942927300,"user_tz":-180,"elapsed":510,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"fa411246-b0a6-4f9f-c6a6-200d755a14a6"},"source":["print(\"Params to learn:\")\r\n","params_to_update = []\r\n","for name,param in model.named_parameters():\r\n","    if param.requires_grad == True:\r\n","        params_to_update.append(param)\r\n","        print(\"\\t\",name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t conv1.weight\n","\t bn1.weight\n","\t bn1.bias\n","\t layer1.0.conv1.weight\n","\t layer1.0.bn1.weight\n","\t layer1.0.bn1.bias\n","\t layer1.0.conv2.weight\n","\t layer1.0.bn2.weight\n","\t layer1.0.bn2.bias\n","\t layer1.1.conv1.weight\n","\t layer1.1.bn1.weight\n","\t layer1.1.bn1.bias\n","\t layer1.1.conv2.weight\n","\t layer1.1.bn2.weight\n","\t layer1.1.bn2.bias\n","\t layer2.0.conv1.weight\n","\t layer2.0.bn1.weight\n","\t layer2.0.bn1.bias\n","\t layer2.0.conv2.weight\n","\t layer2.0.bn2.weight\n","\t layer2.0.bn2.bias\n","\t layer2.0.downsample.0.weight\n","\t layer2.0.downsample.1.weight\n","\t layer2.0.downsample.1.bias\n","\t layer2.1.conv1.weight\n","\t layer2.1.bn1.weight\n","\t layer2.1.bn1.bias\n","\t layer2.1.conv2.weight\n","\t layer2.1.bn2.weight\n","\t layer2.1.bn2.bias\n","\t layer3.0.conv1.weight\n","\t layer3.0.bn1.weight\n","\t layer3.0.bn1.bias\n","\t layer3.0.conv2.weight\n","\t layer3.0.bn2.weight\n","\t layer3.0.bn2.bias\n","\t layer3.0.downsample.0.weight\n","\t layer3.0.downsample.1.weight\n","\t layer3.0.downsample.1.bias\n","\t layer3.1.conv1.weight\n","\t layer3.1.bn1.weight\n","\t layer3.1.bn1.bias\n","\t layer3.1.conv2.weight\n","\t layer3.1.bn2.weight\n","\t layer3.1.bn2.bias\n","\t layer4.0.conv1.weight\n","\t layer4.0.bn1.weight\n","\t layer4.0.bn1.bias\n","\t layer4.0.conv2.weight\n","\t layer4.0.bn2.weight\n","\t layer4.0.bn2.bias\n","\t layer4.0.downsample.0.weight\n","\t layer4.0.downsample.1.weight\n","\t layer4.0.downsample.1.bias\n","\t layer4.1.conv1.weight\n","\t layer4.1.bn1.weight\n","\t layer4.1.bn1.bias\n","\t layer4.1.conv2.weight\n","\t layer4.1.bn2.weight\n","\t layer4.1.bn2.bias\n","\t fc.weight\n","\t fc.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kQiwPHWVO3iq"},"source":["def evaluate_accuracy(data_iter, net, dev):\r\n","    acc_sum, n = torch.Tensor([0]).to(dev), 0\r\n","    net.eval()\r\n","    for X, y in data_iter:\r\n","        X, y = X.to(dev), y.to(dev)\r\n","        acc_sum += (net(X).argmax(axis=1) == y).sum()\r\n","        n += y.shape[0]\r\n","    return acc_sum.item() / n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nPS-bk-hO3kH"},"source":["def train(net, train_iter, test_iter, trainer, num_epochs, dev):\r\n","    loss = nn.CrossEntropyLoss(reduction='sum')\r\n","    net.train()\r\n","    for epoch in range(num_epochs):\r\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\r\n","        for X, y in train_iter:\r\n","            trainer.zero_grad()\r\n","            X, y = X.to(dev), y.to(dev)\r\n","            y_hat = net(X)\r\n","            l = loss(y_hat, y)\r\n","            l.backward()\r\n","            trainer.step()\r\n","            train_l_sum += l.item()\r\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\r\n","            n += y.shape[0]\r\n","            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\r\n","                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\r\n","        test_acc = evaluate_accuracy(test_iter, net, dev)\r\n","        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\r\n","              'time %.1f sec'\r\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\r\n","                 time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEMBErftPDcU","executionInfo":{"status":"ok","timestamp":1613943737662,"user_tz":-180,"elapsed":791906,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"f5833e0f-02b7-45cb-9a36-421fc32829b7"},"source":["lr, num_epochs = 0.001, 10\r\n","trainer = torch.optim.Adam(model.parameters(), lr=lr)\r\n","train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Step. time since epoch: 10.941. Train acc: 0.375. Train Loss: 25.329\n","Step. time since epoch: 19.332. Train acc: 0.844. Train Loss: 10.661\n","Step. time since epoch: 27.865. Train acc: 0.906. Train Loss: 7.802\n","Step. time since epoch: 36.214. Train acc: 0.875. Train Loss: 20.955\n","Step. time since epoch: 44.578. Train acc: 0.812. Train Loss: 16.322\n","Step. time since epoch: 52.910. Train acc: 0.812. Train Loss: 21.766\n","Step. time since epoch: 61.249. Train acc: 0.781. Train Loss: 34.898\n","Step. time since epoch: 66.282. Train acc: 0.750. Train Loss: 23.966\n","epoch 1, loss 0.6627, train acc 0.770, test acc 0.719, time 81.7 sec\n","Step. time since epoch: 10.800. Train acc: 0.781. Train Loss: 31.196\n","Step. time since epoch: 18.685. Train acc: 0.469. Train Loss: 307.482\n","Step. time since epoch: 26.655. Train acc: 0.625. Train Loss: 22.559\n","Step. time since epoch: 34.601. Train acc: 0.500. Train Loss: 22.788\n","Step. time since epoch: 42.629. Train acc: 0.531. Train Loss: 58.193\n","Step. time since epoch: 50.649. Train acc: 0.469. Train Loss: 26.569\n","Step. time since epoch: 58.591. Train acc: 0.594. Train Loss: 21.610\n","Step. time since epoch: 63.337. Train acc: 0.450. Train Loss: 38.726\n","epoch 2, loss 2.1685, train acc 0.557, test acc 0.458, time 78.9 sec\n","Step. time since epoch: 10.742. Train acc: 0.500. Train Loss: 25.101\n","Step. time since epoch: 18.675. Train acc: 0.531. Train Loss: 24.694\n","Step. time since epoch: 26.685. Train acc: 0.500. Train Loss: 24.049\n","Step. time since epoch: 34.600. Train acc: 0.531. Train Loss: 107.214\n","Step. time since epoch: 42.540. Train acc: 0.594. Train Loss: 23.792\n","Step. time since epoch: 50.475. Train acc: 0.531. Train Loss: 22.947\n","Step. time since epoch: 58.396. Train acc: 0.500. Train Loss: 22.143\n","Step. time since epoch: 63.115. Train acc: 0.650. Train Loss: 13.527\n","epoch 3, loss 1.0798, train acc 0.537, test acc 0.458, time 78.7 sec\n","Step. time since epoch: 10.857. Train acc: 0.531. Train Loss: 22.899\n","Step. time since epoch: 18.840. Train acc: 0.406. Train Loss: 23.954\n","Step. time since epoch: 26.877. Train acc: 0.562. Train Loss: 21.813\n","Step. time since epoch: 34.842. Train acc: 0.469. Train Loss: 26.212\n","Step. time since epoch: 42.812. Train acc: 0.562. Train Loss: 22.245\n","Step. time since epoch: 50.792. Train acc: 0.375. Train Loss: 23.686\n","Step. time since epoch: 58.772. Train acc: 0.500. Train Loss: 22.180\n","Step. time since epoch: 63.534. Train acc: 0.550. Train Loss: 13.875\n","epoch 4, loss 0.7249, train acc 0.492, test acc 0.458, time 79.1 sec\n","Step. time since epoch: 10.863. Train acc: 0.594. Train Loss: 21.650\n","Step. time since epoch: 18.842. Train acc: 0.719. Train Loss: 20.088\n","Step. time since epoch: 26.771. Train acc: 0.375. Train Loss: 27.286\n","Step. time since epoch: 34.670. Train acc: 0.469. Train Loss: 23.467\n","Step. time since epoch: 42.588. Train acc: 0.469. Train Loss: 22.653\n","Step. time since epoch: 50.462. Train acc: 0.469. Train Loss: 22.201\n","Step. time since epoch: 58.399. Train acc: 0.500. Train Loss: 22.218\n","Step. time since epoch: 63.136. Train acc: 0.700. Train Loss: 13.435\n","epoch 5, loss 0.7090, train acc 0.529, test acc 0.542, time 78.8 sec\n","Step. time since epoch: 10.826. Train acc: 0.312. Train Loss: 23.820\n","Step. time since epoch: 18.730. Train acc: 0.406. Train Loss: 22.315\n","Step. time since epoch: 26.643. Train acc: 0.469. Train Loss: 22.334\n","Step. time since epoch: 34.581. Train acc: 0.562. Train Loss: 22.037\n","Step. time since epoch: 42.851. Train acc: 0.531. Train Loss: 22.133\n","Step. time since epoch: 50.813. Train acc: 0.281. Train Loss: 23.008\n","Step. time since epoch: 58.712. Train acc: 0.406. Train Loss: 22.263\n","Step. time since epoch: 63.402. Train acc: 0.500. Train Loss: 13.875\n","epoch 6, loss 0.7040, train acc 0.430, test acc 0.542, time 79.0 sec\n","Step. time since epoch: 10.804. Train acc: 0.469. Train Loss: 22.528\n","Step. time since epoch: 18.705. Train acc: 0.500. Train Loss: 22.348\n","Step. time since epoch: 26.614. Train acc: 0.531. Train Loss: 22.089\n","Step. time since epoch: 34.534. Train acc: 0.594. Train Loss: 21.769\n","Step. time since epoch: 42.417. Train acc: 0.281. Train Loss: 23.741\n","Step. time since epoch: 50.372. Train acc: 0.500. Train Loss: 22.247\n","Step. time since epoch: 58.307. Train acc: 0.531. Train Loss: 22.114\n","Step. time since epoch: 63.113. Train acc: 0.600. Train Loss: 13.735\n","epoch 7, loss 0.6991, train acc 0.496, test acc 0.542, time 78.7 sec\n","Step. time since epoch: 10.738. Train acc: 0.438. Train Loss: 22.320\n","Step. time since epoch: 18.677. Train acc: 0.625. Train Loss: 22.003\n","Step. time since epoch: 26.566. Train acc: 0.375. Train Loss: 22.415\n","Step. time since epoch: 34.506. Train acc: 0.438. Train Loss: 22.248\n","Step. time since epoch: 42.382. Train acc: 0.469. Train Loss: 22.176\n","Step. time since epoch: 50.285. Train acc: 0.531. Train Loss: 22.150\n","Step. time since epoch: 58.220. Train acc: 0.406. Train Loss: 22.565\n","Step. time since epoch: 63.043. Train acc: 0.400. Train Loss: 13.974\n","epoch 8, loss 0.6961, train acc 0.463, test acc 0.458, time 78.6 sec\n","Step. time since epoch: 10.919. Train acc: 0.594. Train Loss: 22.164\n","Step. time since epoch: 18.862. Train acc: 0.531. Train Loss: 22.167\n","Step. time since epoch: 26.782. Train acc: 0.500. Train Loss: 22.183\n","Step. time since epoch: 34.746. Train acc: 0.375. Train Loss: 22.229\n","Step. time since epoch: 42.728. Train acc: 0.562. Train Loss: 22.154\n","Step. time since epoch: 50.739. Train acc: 0.719. Train Loss: 22.118\n","Step. time since epoch: 58.674. Train acc: 0.406. Train Loss: 22.246\n","Step. time since epoch: 63.386. Train acc: 0.500. Train Loss: 13.856\n","epoch 9, loss 0.6931, train acc 0.525, test acc 0.542, time 79.0 sec\n","Step. time since epoch: 10.761. Train acc: 0.656. Train Loss: 21.993\n","Step. time since epoch: 18.684. Train acc: 0.531. Train Loss: 22.112\n","Step. time since epoch: 26.560. Train acc: 0.531. Train Loss: 22.104\n","Step. time since epoch: 34.644. Train acc: 0.406. Train Loss: 22.435\n","Step. time since epoch: 42.667. Train acc: 0.469. Train Loss: 22.305\n","Step. time since epoch: 50.733. Train acc: 0.469. Train Loss: 22.282\n","Step. time since epoch: 58.640. Train acc: 0.469. Train Loss: 22.278\n","Step. time since epoch: 63.378. Train acc: 0.400. Train Loss: 14.046\n","epoch 10, loss 0.6949, train acc 0.496, test acc 0.542, time 78.9 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Da-2NqZoPMtc"},"source":["# release CUDA\r\n","model.eval()\r\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6MQvU-O7POt0"},"source":["## **VGG 16 FineTuning (pretrained) + augmentation**"]},{"cell_type":"code","metadata":{"id":"ntgunHZ4PaGU"},"source":["model = models.vgg16(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCRWm0MkPmK3"},"source":["model = model.to(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGr1nj-KPqVj"},"source":["## Убираем требование градиента:\r\n","for param in model.parameters():\r\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rg5u2DrPPqXS","executionInfo":{"status":"ok","timestamp":1613943795366,"user_tz":-180,"elapsed":543,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"dea85435-6e1c-4c73-fc56-8cf4338141b0"},"source":["model.classifier"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=25088, out_features=4096, bias=True)\n","  (1): ReLU(inplace=True)\n","  (2): Dropout(p=0.5, inplace=False)\n","  (3): Linear(in_features=4096, out_features=4096, bias=True)\n","  (4): ReLU(inplace=True)\n","  (5): Dropout(p=0.5, inplace=False)\n","  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"njOScMg4P29D"},"source":["model.classifier[6] = nn.Linear(in_features=4096, out_features=2).to(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uk3cwuCwP6r1","executionInfo":{"status":"ok","timestamp":1613943812784,"user_tz":-180,"elapsed":516,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"723ea2f1-f46d-406c-bc5a-1de44818726e"},"source":["print(\"Params to learn:\")\r\n","params_to_update = []\r\n","for name,param in model.named_parameters():\r\n","    if param.requires_grad == True:\r\n","        params_to_update.append(param)\r\n","        print(\"\\t\",name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t classifier.6.weight\n","\t classifier.6.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bvbwAOvhP-np"},"source":["def evaluate_accuracy(data_iter, net, dev):\r\n","    acc_sum, n = torch.Tensor([0]).to(dev), 0\r\n","    net.eval()\r\n","    for X, y in data_iter:\r\n","        X, y = X.to(dev), y.to(dev)\r\n","        acc_sum += (net(X).argmax(axis=1) == y).sum()\r\n","        n += y.shape[0]\r\n","    return acc_sum.item() / n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DoGIi6VTQENV"},"source":["def train(net, train_iter, test_iter, trainer, num_epochs, dev):\r\n","    loss = nn.CrossEntropyLoss(reduction='sum')\r\n","    net.train()\r\n","    for epoch in range(num_epochs):\r\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\r\n","        for X, y in train_iter:\r\n","            trainer.zero_grad()\r\n","            X, y = X.to(dev), y.to(dev)\r\n","            y_hat = net(X)\r\n","            l = loss(y_hat, y)\r\n","            l.backward()\r\n","            trainer.step()\r\n","            train_l_sum += l.item()\r\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\r\n","            n += y.shape[0]\r\n","            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\r\n","                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\r\n","        test_acc = evaluate_accuracy(test_iter, net, dev)\r\n","        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\r\n","              'time %.1f sec'\r\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\r\n","                 time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiB9bvwSQJrs","executionInfo":{"status":"ok","timestamp":1613945978900,"user_tz":-180,"elapsed":2149822,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"14b88cdb-4f0a-4e91-bd24-1cfbd66684e8"},"source":["lr, num_epochs = 0.001, 10\r\n","trainer = torch.optim.Adam(model.parameters(), lr=lr)\r\n","train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Step. time since epoch: 20.598. Train acc: 0.625. Train Loss: 22.634\n","Step. time since epoch: 37.339. Train acc: 0.719. Train Loss: 19.483\n","Step. time since epoch: 54.100. Train acc: 0.844. Train Loss: 13.176\n","Step. time since epoch: 70.945. Train acc: 0.875. Train Loss: 10.633\n","Step. time since epoch: 87.685. Train acc: 0.875. Train Loss: 9.035\n","Step. time since epoch: 104.404. Train acc: 0.938. Train Loss: 9.971\n","Step. time since epoch: 121.155. Train acc: 0.844. Train Loss: 11.402\n","Step. time since epoch: 131.732. Train acc: 0.950. Train Loss: 3.836\n","epoch 1, loss 0.4105, train acc 0.828, test acc 0.961, time 215.6 sec\n","Step. time since epoch: 20.229. Train acc: 0.969. Train Loss: 4.856\n","Step. time since epoch: 36.990. Train acc: 1.000. Train Loss: 2.919\n","Step. time since epoch: 53.770. Train acc: 1.000. Train Loss: 2.424\n","Step. time since epoch: 70.555. Train acc: 0.906. Train Loss: 5.035\n","Step. time since epoch: 87.323. Train acc: 0.938. Train Loss: 5.409\n","Step. time since epoch: 104.094. Train acc: 1.000. Train Loss: 2.561\n","Step. time since epoch: 120.892. Train acc: 0.844. Train Loss: 7.533\n","Step. time since epoch: 131.480. Train acc: 0.950. Train Loss: 3.096\n","epoch 2, loss 0.1387, train acc 0.951, test acc 0.961, time 214.9 sec\n","Step. time since epoch: 20.130. Train acc: 0.938. Train Loss: 5.734\n","Step. time since epoch: 36.899. Train acc: 1.000. Train Loss: 2.722\n","Step. time since epoch: 53.618. Train acc: 0.875. Train Loss: 5.888\n","Step. time since epoch: 70.575. Train acc: 0.969. Train Loss: 2.851\n","Step. time since epoch: 87.375. Train acc: 0.906. Train Loss: 9.669\n","Step. time since epoch: 104.078. Train acc: 0.938. Train Loss: 3.411\n","Step. time since epoch: 120.810. Train acc: 0.906. Train Loss: 6.422\n","Step. time since epoch: 131.376. Train acc: 0.950. Train Loss: 1.868\n","epoch 3, loss 0.1581, train acc 0.934, test acc 0.961, time 214.8 sec\n","Step. time since epoch: 20.220. Train acc: 0.906. Train Loss: 4.341\n","Step. time since epoch: 37.063. Train acc: 1.000. Train Loss: 1.448\n","Step. time since epoch: 53.849. Train acc: 0.938. Train Loss: 3.364\n","Step. time since epoch: 70.599. Train acc: 0.906. Train Loss: 5.123\n","Step. time since epoch: 87.356. Train acc: 0.938. Train Loss: 3.701\n","Step. time since epoch: 104.094. Train acc: 0.969. Train Loss: 2.749\n","Step. time since epoch: 121.046. Train acc: 0.938. Train Loss: 2.937\n","Step. time since epoch: 131.606. Train acc: 0.950. Train Loss: 5.076\n","epoch 4, loss 0.1178, train acc 0.943, test acc 0.967, time 215.5 sec\n","Step. time since epoch: 20.247. Train acc: 0.969. Train Loss: 3.704\n","Step. time since epoch: 37.030. Train acc: 0.938. Train Loss: 4.766\n","Step. time since epoch: 53.895. Train acc: 0.969. Train Loss: 2.495\n","Step. time since epoch: 70.631. Train acc: 0.875. Train Loss: 9.293\n","Step. time since epoch: 87.420. Train acc: 1.000. Train Loss: 0.517\n","Step. time since epoch: 104.153. Train acc: 0.969. Train Loss: 3.145\n","Step. time since epoch: 120.956. Train acc: 0.844. Train Loss: 9.722\n","Step. time since epoch: 131.549. Train acc: 1.000. Train Loss: 0.720\n","epoch 5, loss 0.1408, train acc 0.943, test acc 0.961, time 215.0 sec\n","Step. time since epoch: 20.243. Train acc: 0.969. Train Loss: 1.979\n","Step. time since epoch: 36.983. Train acc: 0.969. Train Loss: 4.019\n","Step. time since epoch: 54.052. Train acc: 0.938. Train Loss: 4.314\n","Step. time since epoch: 70.869. Train acc: 0.906. Train Loss: 5.323\n","Step. time since epoch: 87.622. Train acc: 0.938. Train Loss: 2.803\n","Step. time since epoch: 104.418. Train acc: 0.969. Train Loss: 2.841\n","Step. time since epoch: 121.196. Train acc: 0.969. Train Loss: 3.440\n","Step. time since epoch: 131.779. Train acc: 0.900. Train Loss: 3.613\n","epoch 6, loss 0.1161, train acc 0.947, test acc 0.967, time 215.3 sec\n","Step. time since epoch: 20.216. Train acc: 0.969. Train Loss: 2.479\n","Step. time since epoch: 37.007. Train acc: 0.969. Train Loss: 2.930\n","Step. time since epoch: 53.750. Train acc: 1.000. Train Loss: 1.547\n","Step. time since epoch: 70.689. Train acc: 0.969. Train Loss: 4.006\n","Step. time since epoch: 87.440. Train acc: 1.000. Train Loss: 2.609\n","Step. time since epoch: 104.192. Train acc: 0.938. Train Loss: 3.861\n","Step. time since epoch: 120.912. Train acc: 1.000. Train Loss: 1.252\n","Step. time since epoch: 131.475. Train acc: 1.000. Train Loss: 1.035\n","epoch 7, loss 0.0808, train acc 0.980, test acc 0.974, time 215.0 sec\n","Step. time since epoch: 20.339. Train acc: 0.938. Train Loss: 4.689\n","Step. time since epoch: 37.059. Train acc: 0.969. Train Loss: 3.752\n","Step. time since epoch: 53.819. Train acc: 0.969. Train Loss: 2.607\n","Step. time since epoch: 70.591. Train acc: 1.000. Train Loss: 2.585\n","Step. time since epoch: 87.363. Train acc: 1.000. Train Loss: 1.147\n","Step. time since epoch: 104.140. Train acc: 1.000. Train Loss: 1.857\n","Step. time since epoch: 120.834. Train acc: 0.969. Train Loss: 2.509\n","Step. time since epoch: 131.365. Train acc: 1.000. Train Loss: 0.556\n","epoch 8, loss 0.0807, train acc 0.980, test acc 0.954, time 214.6 sec\n","Step. time since epoch: 20.127. Train acc: 1.000. Train Loss: 1.470\n","Step. time since epoch: 36.963. Train acc: 0.969. Train Loss: 1.863\n","Step. time since epoch: 53.685. Train acc: 1.000. Train Loss: 1.567\n","Step. time since epoch: 70.346. Train acc: 0.938. Train Loss: 3.468\n","Step. time since epoch: 87.015. Train acc: 0.938. Train Loss: 5.198\n","Step. time since epoch: 103.803. Train acc: 1.000. Train Loss: 1.822\n","Step. time since epoch: 120.523. Train acc: 0.969. Train Loss: 2.436\n","Step. time since epoch: 131.075. Train acc: 1.000. Train Loss: 1.728\n","epoch 9, loss 0.0801, train acc 0.975, test acc 0.967, time 214.3 sec\n","Step. time since epoch: 20.300. Train acc: 1.000. Train Loss: 2.101\n","Step. time since epoch: 37.031. Train acc: 1.000. Train Loss: 1.194\n","Step. time since epoch: 53.750. Train acc: 0.969. Train Loss: 2.206\n","Step. time since epoch: 70.458. Train acc: 1.000. Train Loss: 2.035\n","Step. time since epoch: 87.130. Train acc: 0.906. Train Loss: 4.538\n","Step. time since epoch: 103.805. Train acc: 1.000. Train Loss: 0.692\n","Step. time since epoch: 120.542. Train acc: 1.000. Train Loss: 0.905\n","Step. time since epoch: 131.204. Train acc: 0.900. Train Loss: 3.642\n","epoch 10, loss 0.0710, train acc 0.975, test acc 0.967, time 214.3 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pthANfxtQQgD"},"source":["## **Сравните качество всех трёх подходов.**"]},{"cell_type":"markdown","metadata":{"id":"_YvVwLDQQcn2"},"source":["Обучение моделей ResNet 18 и VGG 16 выдаёт совсем плохой результат. Применение FineTuning, обучение на заранее тренированной модели, даёт практически стопроцентный результат. Аугментация придаёт стабильность результатам."]},{"cell_type":"markdown","metadata":{"id":"XyoXGx8rSSAf"},"source":["# **Задание ***  \r\n","# **Примените FineTuning ResNet 18 к FashionMnist.**  \r\n","# **Удалось ли увидеть резкое увеличение качества?**  \r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"_v1wXyinSlYU"},"source":["BATCH_SIZE = 256"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":413,"referenced_widgets":["428437bf7c664721a748b67637f21cc0","4ac121f645bd4676a77400d0db460a8b","2f7cd2fa2ac047d8845b0adf8a25f2df","ea0ac53f3d8341d7a8bd19651860c1ba","95082ec51eb54cb6982c40997a3d8761","eedff8e203bf445c8528bbb8fa81a9a1","dc7014fb2f22476b91255388c35448f0","5ea9902fbb18431383ebe9814b9ac972","c04f30f7df1647b49eaa80d8a322b358","adfe91a54641492bb4109c250d39a203","603f3576e0dd493ba0bb6fa8c44ed138","cbae3e80765942a281efa415fa468a77","fa43819ea543420f9710f056b6a693bc","bcaead8ffa724ec4b308fbd4f3785546","10bf2f74b8be4c90ad54faee547e1445","55b15d60f6e54e72884436c4156aacf9","4950a587aff24cfcad29b7d938699618","ee8e8066143c408bb1c6ee2d11c3f2ef","c47205eeb66e4ac5a617e4c6a09cc207","ccb7ad8a2d494d93a2eab42152d9fc7d","e74ca2864f054ac1bac6409bf3414c5e","fca0da89983f4c81b0c1dee1bf4668c3","36d4a2e6c862409c891dbb983d672fce","33b5fca0e4fc4dcbb1d643bed404c912","3f88dbc9647c4a2cb1eaf659c31e3687","13c3825417484f9193e0571d8f72cfbc","590d7fd932fc4733adfc164eca3288f5","30f20870495149b2894e34b017d6ce99","a9dd7773ffd5416ab34afee60363815e","a914d1b620d94d3494feade98af63000","aa17f5640a4a45fa8aaa76b50840cbe5","fe0daede8344411887d39b23140cc362"]},"id":"QDONQW6jSppJ","executionInfo":{"status":"ok","timestamp":1613946008374,"user_tz":-180,"elapsed":2092,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"d20a355b-a7ae-4e56-a4aa-58eef8abb4c3"},"source":["_transforms = tv.transforms.Compose([\r\n","    tv.transforms.Grayscale(3),\r\n","    tv.transforms.Resize((224,224)),\r\n","    tv.transforms.ToTensor()\r\n","])\r\n","train_dataset = tv.datasets.MNIST('.', train=True, transform=_transforms, download=True)\r\n","test_dataset = tv.datasets.MNIST('.', train=False, transform=_transforms, download=True)\r\n","train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\r\n","test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"428437bf7c664721a748b67637f21cc0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c04f30f7df1647b49eaa80d8a322b358","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n","\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4950a587aff24cfcad29b7d938699618","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f88dbc9647c4a2cb1eaf659c31e3687","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-BsmvUZHTLdU"},"source":["model = tv.models.resnet18(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0NayWAMTT3b"},"source":["model = model.to(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"koz7z9QQTXlD"},"source":["## Убираем требование градиента:\r\n","for param in model.parameters():\r\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImMn2fMFTeUI","executionInfo":{"status":"ok","timestamp":1613946031257,"user_tz":-180,"elapsed":536,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"6be069cb-3143-4eaa-e40b-f618f70e1098"},"source":["model.fc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=512, out_features=1000, bias=True)"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"code","metadata":{"id":"GMQdYJTYTeVq"},"source":["model.fc = nn.Linear(in_features=512, out_features=10).to(dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJGbbwxBTvlC","executionInfo":{"status":"ok","timestamp":1613946035748,"user_tz":-180,"elapsed":622,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"5f2bdc5a-c4fc-4fe8-8c6a-befb9220cac0"},"source":["print(\"Params to learn:\")\r\n","params_to_update = []\r\n","for name,param in model.named_parameters():\r\n","    if param.requires_grad == True:\r\n","        params_to_update.append(param)\r\n","        print(\"\\t\",name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t fc.weight\n","\t fc.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BeQtO_wOT0Vu"},"source":["def evaluate_accuracy(data_iter, net, dev):\r\n","    acc_sum, n = torch.Tensor([0]).to(dev), 0\r\n","    for X, y in data_iter:\r\n","        X, y = X.to(dev), y.to(dev)\r\n","        acc_sum += (net(X).argmax(axis=1) == y).sum()\r\n","        n += y.shape[0]\r\n","    return acc_sum.item() / n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kTyt8SU7T0Xm"},"source":["def train(net, train_iter, test_iter, trainer, num_epochs, dev):\r\n","    loss = nn.CrossEntropyLoss(reduction='sum')\r\n","    net.train()\r\n","    for epoch in range(num_epochs):\r\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\r\n","        for X, y in train_iter:\r\n","            trainer.zero_grad()\r\n","            X, y = X.to(dev), y.to(dev)\r\n","            y_hat = net(X)\r\n","            l = loss(y_hat, y)\r\n","            l.backward()\r\n","            trainer.step()\r\n","            train_l_sum += l.item()\r\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\r\n","            n += y.shape[0]\r\n","            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\r\n","                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\r\n","        test_acc = evaluate_accuracy(test_iter, net, dev)\r\n","        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\r\n","              'time %.1f sec'\r\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\r\n","                 time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5BeucCi2T-jx","executionInfo":{"status":"error","timestamp":1613948297363,"user_tz":-180,"elapsed":2249200,"user":{"displayName":"Дмитрий Зеленин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipAVqvGUDyzuPjOfJR-p9zFprHJyE0eR-cN_rS6Q=s64","userId":"06754578418295277569"}},"outputId":"225aafcf-8219-45fe-cd9e-0ced3dba0035"},"source":["lr, num_epochs = 0.001, 10\r\n","trainer = torch.optim.Adam(model.parameters(), lr=lr)\r\n","train(model, train_iter, test_iter, trainer, num_epochs, dev)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Step. time since epoch: 21.348. Train acc: 0.121. Train Loss: 678.064\n","Step. time since epoch: 42.384. Train acc: 0.117. Train Loss: 623.940\n","Step. time since epoch: 63.294. Train acc: 0.152. Train Loss: 573.069\n","Step. time since epoch: 84.168. Train acc: 0.188. Train Loss: 556.026\n","Step. time since epoch: 105.184. Train acc: 0.207. Train Loss: 548.091\n","Step. time since epoch: 126.013. Train acc: 0.211. Train Loss: 549.575\n","Step. time since epoch: 146.943. Train acc: 0.270. Train Loss: 519.869\n","Step. time since epoch: 168.033. Train acc: 0.312. Train Loss: 511.276\n","Step. time since epoch: 189.009. Train acc: 0.359. Train Loss: 494.909\n","Step. time since epoch: 210.151. Train acc: 0.410. Train Loss: 494.599\n","Step. time since epoch: 231.226. Train acc: 0.469. Train Loss: 462.397\n","Step. time since epoch: 252.115. Train acc: 0.527. Train Loss: 454.913\n","Step. time since epoch: 273.084. Train acc: 0.621. Train Loss: 427.346\n","Step. time since epoch: 294.086. Train acc: 0.625. Train Loss: 420.656\n","Step. time since epoch: 315.082. Train acc: 0.621. Train Loss: 406.918\n","Step. time since epoch: 335.958. Train acc: 0.676. Train Loss: 399.901\n","Step. time since epoch: 356.924. Train acc: 0.648. Train Loss: 388.405\n","Step. time since epoch: 377.783. Train acc: 0.719. Train Loss: 370.114\n","Step. time since epoch: 398.728. Train acc: 0.652. Train Loss: 374.519\n","Step. time since epoch: 419.508. Train acc: 0.727. Train Loss: 363.928\n","Step. time since epoch: 440.454. Train acc: 0.730. Train Loss: 356.287\n","Step. time since epoch: 461.341. Train acc: 0.707. Train Loss: 344.161\n","Step. time since epoch: 482.436. Train acc: 0.727. Train Loss: 340.737\n","Step. time since epoch: 503.339. Train acc: 0.738. Train Loss: 339.844\n","Step. time since epoch: 524.398. Train acc: 0.723. Train Loss: 327.116\n","Step. time since epoch: 545.252. Train acc: 0.812. Train Loss: 293.025\n","Step. time since epoch: 566.188. Train acc: 0.762. Train Loss: 308.574\n","Step. time since epoch: 586.996. Train acc: 0.797. Train Loss: 294.424\n","Step. time since epoch: 608.020. Train acc: 0.773. Train Loss: 302.357\n","Step. time since epoch: 628.839. Train acc: 0.812. Train Loss: 274.630\n","Step. time since epoch: 649.775. Train acc: 0.812. Train Loss: 287.428\n","Step. time since epoch: 670.625. Train acc: 0.785. Train Loss: 270.665\n","Step. time since epoch: 691.561. Train acc: 0.812. Train Loss: 277.708\n","Step. time since epoch: 712.438. Train acc: 0.734. Train Loss: 302.182\n","Step. time since epoch: 733.401. Train acc: 0.801. Train Loss: 279.774\n","Step. time since epoch: 754.236. Train acc: 0.887. Train Loss: 212.264\n","Step. time since epoch: 775.200. Train acc: 0.805. Train Loss: 245.904\n","Step. time since epoch: 796.200. Train acc: 0.844. Train Loss: 240.193\n","Step. time since epoch: 817.180. Train acc: 0.863. Train Loss: 214.903\n","Step. time since epoch: 838.089. Train acc: 0.770. Train Loss: 245.437\n","Step. time since epoch: 859.035. Train acc: 0.809. Train Loss: 245.002\n","Step. time since epoch: 879.884. Train acc: 0.859. Train Loss: 206.877\n","Step. time since epoch: 900.894. Train acc: 0.887. Train Loss: 212.678\n","Step. time since epoch: 921.842. Train acc: 0.852. Train Loss: 218.826\n","Step. time since epoch: 942.858. Train acc: 0.863. Train Loss: 201.626\n","Step. time since epoch: 963.804. Train acc: 0.914. Train Loss: 203.535\n","Step. time since epoch: 984.821. Train acc: 0.848. Train Loss: 212.383\n","Step. time since epoch: 1005.770. Train acc: 0.883. Train Loss: 202.641\n","Step. time since epoch: 1026.829. Train acc: 0.883. Train Loss: 204.906\n","Step. time since epoch: 1047.692. Train acc: 0.859. Train Loss: 203.810\n","Step. time since epoch: 1068.753. Train acc: 0.859. Train Loss: 222.508\n","Step. time since epoch: 1089.636. Train acc: 0.848. Train Loss: 220.315\n","Step. time since epoch: 1110.789. Train acc: 0.938. Train Loss: 169.364\n","Step. time since epoch: 1131.717. Train acc: 0.883. Train Loss: 182.894\n","Step. time since epoch: 1152.722. Train acc: 0.875. Train Loss: 199.197\n","Step. time since epoch: 1173.677. Train acc: 0.875. Train Loss: 186.112\n","Step. time since epoch: 1194.706. Train acc: 0.832. Train Loss: 203.693\n","Step. time since epoch: 1215.666. Train acc: 0.902. Train Loss: 185.625\n","Step. time since epoch: 1236.673. Train acc: 0.887. Train Loss: 164.581\n","Step. time since epoch: 1257.554. Train acc: 0.906. Train Loss: 156.166\n","Step. time since epoch: 1278.575. Train acc: 0.879. Train Loss: 161.204\n","Step. time since epoch: 1299.565. Train acc: 0.852. Train Loss: 182.722\n","Step. time since epoch: 1320.588. Train acc: 0.863. Train Loss: 190.294\n","Step. time since epoch: 1341.508. Train acc: 0.918. Train Loss: 144.182\n","Step. time since epoch: 1362.533. Train acc: 0.930. Train Loss: 126.733\n","Step. time since epoch: 1383.412. Train acc: 0.863. Train Loss: 164.678\n","Step. time since epoch: 1404.446. Train acc: 0.875. Train Loss: 170.037\n","Step. time since epoch: 1426.234. Train acc: 0.883. Train Loss: 159.877\n","Step. time since epoch: 1447.267. Train acc: 0.855. Train Loss: 187.504\n","Step. time since epoch: 1468.127. Train acc: 0.883. Train Loss: 169.399\n","Step. time since epoch: 1489.115. Train acc: 0.945. Train Loss: 120.063\n","Step. time since epoch: 1509.953. Train acc: 0.895. Train Loss: 139.752\n","Step. time since epoch: 1530.994. Train acc: 0.910. Train Loss: 143.060\n","Step. time since epoch: 1551.942. Train acc: 0.914. Train Loss: 125.150\n","Step. time since epoch: 1572.869. Train acc: 0.910. Train Loss: 137.204\n","Step. time since epoch: 1593.752. Train acc: 0.891. Train Loss: 142.624\n","Step. time since epoch: 1614.835. Train acc: 0.883. Train Loss: 141.918\n","Step. time since epoch: 1635.695. Train acc: 0.891. Train Loss: 146.114\n","Step. time since epoch: 1656.706. Train acc: 0.895. Train Loss: 146.323\n","Step. time since epoch: 1677.676. Train acc: 0.914. Train Loss: 130.831\n","Step. time since epoch: 1698.653. Train acc: 0.922. Train Loss: 128.705\n","Step. time since epoch: 1719.577. Train acc: 0.902. Train Loss: 140.884\n","Step. time since epoch: 1740.717. Train acc: 0.926. Train Loss: 122.051\n","Step. time since epoch: 1761.645. Train acc: 0.922. Train Loss: 123.368\n","Step. time since epoch: 1782.748. Train acc: 0.938. Train Loss: 103.546\n","Step. time since epoch: 1803.619. Train acc: 0.918. Train Loss: 121.509\n","Step. time since epoch: 1824.734. Train acc: 0.875. Train Loss: 144.959\n","Step. time since epoch: 1845.618. Train acc: 0.914. Train Loss: 126.235\n","Step. time since epoch: 1866.586. Train acc: 0.867. Train Loss: 152.955\n","Step. time since epoch: 1887.520. Train acc: 0.898. Train Loss: 128.275\n","Step. time since epoch: 1908.504. Train acc: 0.926. Train Loss: 117.370\n","Step. time since epoch: 1929.330. Train acc: 0.922. Train Loss: 113.607\n","Step. time since epoch: 1950.368. Train acc: 0.914. Train Loss: 118.405\n","Step. time since epoch: 1971.262. Train acc: 0.895. Train Loss: 132.670\n","Step. time since epoch: 1992.220. Train acc: 0.906. Train Loss: 131.347\n","Step. time since epoch: 2013.153. Train acc: 0.879. Train Loss: 137.625\n","Step. time since epoch: 2034.198. Train acc: 0.871. Train Loss: 146.960\n","Step. time since epoch: 2055.253. Train acc: 0.922. Train Loss: 105.901\n","Step. time since epoch: 2076.248. Train acc: 0.910. Train Loss: 110.252\n","Step. time since epoch: 2097.176. Train acc: 0.941. Train Loss: 101.040\n","Step. time since epoch: 2118.136. Train acc: 0.941. Train Loss: 100.554\n","Step. time since epoch: 2139.163. Train acc: 0.906. Train Loss: 115.813\n","Step. time since epoch: 2160.179. Train acc: 0.922. Train Loss: 110.351\n","Step. time since epoch: 2181.087. Train acc: 0.906. Train Loss: 123.139\n","Step. time since epoch: 2202.105. Train acc: 0.895. Train Loss: 123.644\n","Step. time since epoch: 2222.970. Train acc: 0.898. Train Loss: 115.351\n","Step. time since epoch: 2243.941. Train acc: 0.879. Train Loss: 141.074\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-75-46039ec049b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-74-f70c4ca7498e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, trainer, num_epochs, dev)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"e-y2ErKnUR_g"},"source":["Данная модель быстрее обучается и чуть возросло качество с 91% на 94%. Впервые за время 1489.115."]}]}